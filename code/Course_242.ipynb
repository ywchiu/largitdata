{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J9esgcwaz2Nx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "a341cae0-149a-4989-989d-0bbd25d98ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.25.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n"
          ]
        }
      ],
      "source": [
        "# @title ÂÆâË£ù Llama-index „ÄÅ Llama-parse Ëàá OpenAI\n",
        "!pip install llama-index\n",
        "!pip install llama-index-core\n",
        "!pip install llama-index-embeddings-openai\n",
        "!pip install llama-parse\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Â≠òÂèñ Google Drive\n",
        "import os\n",
        "from google.colab import drive\n",
        "THESIS_LOC = '/content/drive/MyDrive/thesis/' # @param {type:\"string\"}\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(THESIS_LOC)\n",
        "os.listdir()"
      ],
      "metadata": {
        "id": "jL6mypYcZxw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "7cc7d34a-4143-4044-8f93-3579b8295ab7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2404.17723.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j-1_9yYkz2N0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Ë®≠ÂÆö llama-parse\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import os\n",
        "LLAMA_PARSER_KEY = 'llx-'  # @param {type:\"string\"}\n",
        "OPENAI_KEY = 'sk-'  # @param {type:\"string\"}\n",
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = LLAMA_PARSER_KEY\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gcd_LcPYz2N0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Ë®≠ÂÆöllama-parse Áî®ÁöÑ LLM Ê®°Âûã\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core import Settings\n",
        "LLM_MODEL = \"gpt-3.5-turbo-0125\"  # @param {type:\"string\"}\n",
        "llm = OpenAI(model=LLM_MODEL)\n",
        "\n",
        "Settings.llm = llm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ËºâÂÖ•PDF\n",
        "from llama_parse import LlamaParse\n",
        "from IPython.display import display, Markdown, Latex\n",
        "import os\n",
        "\n",
        "PDF_FILE = \"2404.17723.pdf\" # @param {type:\"string\"}\n",
        "parser = LlamaParse(result_type=\"markdown\")\n",
        "\n",
        "md_documents = parser.load_data(\n",
        "    file_path=PDF_FILE\n",
        ")\n",
        "\n",
        "print(md_documents[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4cMWhCfr7JA",
        "outputId": "adbc99a7-9d62-4c69-9ea7-4bb17c0102a4",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id df1addcd-818f-45aa-88d2-d3c7a8082221\n",
            "## Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering\n",
            "\n",
            "Zhentao Xu &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Mark Jerome Cruz &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Matthew Guevara\n",
            "\n",
            "zhexu@linkedin.com &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; marcruz@linkedin.com &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mguevara@linkedin.com\n",
            "\n",
            "LinkedIn Corporation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LinkedIn Corporation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LinkedIn Corporation\n",
            "\n",
            "Sunnyvale, CA, USA &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Sunnyvale, CA, USA &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Sunnyvale, CA, USA\n",
            "\n",
            "Tie Wang &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Manasi Deshpande &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Xiaofeng Wang\n",
            "\n",
            "tiewang@linkedin.com &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; madeshpande@linkedin.com &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; xiaofwang@linkedin.com\n",
            "\n",
            "LinkedIn Corporation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LinkedIn Corporation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LinkedIn Corporation\n",
            "\n",
            "Sunnyvale, CA, USA &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Sunnyvale, CA, USA &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Sunnyvale, CA, USA\n",
            "\n",
            "Zheng Li\n",
            "\n",
            "zeli@linkedin.com\n",
            "\n",
            "LinkedIn Corporation\n",
            "\n",
            "Sunnyvale, CA, USA\n",
            "\n",
            "### ABSTRACT\n",
            "\n",
            "In customer service technical support, swiftly and accurately retrieving relevant past issues is critical for efficiently resolving customer inquiries. The conventional retrieval methods in retrieval-augmented generation (RAG) for large language models (LLMs) treat a large corpus of past issue tracking tickets as plain text, ignoring the crucial intra-issue structure and inter-issue relations, which limits performance. We introduce a novel customer service question-answering method that amalgamates RAG with a knowledge graph (KG). Our method constructs a KG from historical issues for use in retrieval, retaining the intra-issue structure and inter-issue relations. During the question-answering phase, our method parses consumer queries and retrieves related sub-graphs from the KG to generate answers. This integration of a KG not only improves retrieval accuracy by preserving customer service structure information but also enhances answering quality by mitigating the effects of text segmentation. Empirical assessments on our benchmark datasets, utilizing key retrieval (MRR, Recall@K, NDCG@K) and text generation (BLEU, ROUGE, METEOR) metrics, reveal that our method outperforms the baseline by 77.6% in MRR and by 0.32 in BLEU. Our method has been deployed within LinkedIn‚Äôs customer service team for approximately six months and has reduced the median per-issue resolution time by 28.6%.\n",
            "\n",
            "### CCS CONCEPTS\n",
            "\n",
            "‚Ä¢ Computing methodologies ‚Üí Information extraction; Natural language generation.\n",
            "\n",
            "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\n",
            "\n",
            "SIGIR ‚Äô24, July 14‚Äì18, 2024, Washington, DC, USA\n",
            "\n",
            "¬© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\n",
            "\n",
            "ACM ISBN 979-8-4007-0431-4/24/07\n",
            "\n",
            "https://doi.org/10.1145/3626772.3661370\n",
            "\n",
            "### ACM Reference Format:\n",
            "\n",
            "Zhentao Xu, Mark Jerome Cruz, Matthew Guevara, Tie Wang, Manasi Deshpande, Xiaofeng Wang, and Zheng Li. 2024. Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ‚Äô24), July 14‚Äì18, 2024, Washington, DC, USA. ACM, New York, NY, USA, 5 pages.\n",
            "\n",
            "https://doi.org/10.1145/3626772.3661370\n",
            "\n",
            "## 1 INTRODUCTION\n",
            "\n",
            "Effective technical support in customer service underpins product success, directly influencing customer satisfaction and loyalty. Given the frequent similarity of customer inquiries to previously resolved issues, the rapid and accurate retrieval of relevant past instances is crucial for the efficient resolution of such inquiries. Recent advancements in embedding-based retrieval (EBR), large language models (LLMs), and retrieval-augmented generation (RAG) have significantly enhanced retrieval performance and question-answering capabilities for the technical support of customer service. This process typically unfolds in two stages: first, historical issue tickets are treated as plain text, segmented into smaller chunks to accommodate the context length constraints of embedding models; each chunk is then converted into an embedding vector for retrieval. Second, during the question-answering phase, the system retrieves the most relevant chunks and feeds them as contexts for LLMs to generate answers in response to queries. Despite its straightforward approach, this method encounters several limitations:\n",
            "\n",
            "- Limitation 1 - Compromised Retrieval Accuracy from Ignoring Structures: Issue tracking documents such as Jira possess inherent structure and are interconnected, with references such as \"issue A is related to/copied from/caused\"\n",
            "---\n",
            "## SIGIR ‚Äô24, July 14‚Äì18, 2024, Washington, DC, USA Zhentao Xu, et al.\n",
            "\n",
            "Limitation 1 - Loss of Intrinsic Relationship: The conventional approach of compressing documents into text chunks leads to the loss of vital information. Our approach parses issue tickets into trees and further connects individual issue tickets to form an interconnected graph, which maintains this intrinsic relationship among entities, achieving high retrieval performance.\n",
            "\n",
            "Limitation 2 - Reduced Answer Quality from Segmentation: Segmenting extensive issue tickets into fixed-length segments to accommodate the context length constraints of embedding models can result in the disconnection of related content, leading to incomplete answers. Our graph-based parsing method overcomes this by preserving the logical coherence of ticket sections, ensuring the delivery of complete and high-quality responses.\n",
            "\n",
            "## RELATED WORK\n",
            "\n",
            "Question answering (QA) with knowledge graphs (KGs) can be broadly classified into retrieval-based, template-based, and semantic parsing-based methods. Retrieval-based approaches utilize relation extraction or distributed representations to derive answers from KGs, but they face difficulties with questions involving multiple entities. Template-based strategies depend on manually-created templates for encoding complex queries, yet are limited by the scope of available templates. Semantic parsing methods map text to logical forms containing predicates from KGs.\n",
            "\n",
            "Recent advancements in large language models (LLMs) integration with Knowledge Graphs (KGs) have demonstrated notable progress. For graph-based reasoning, Think-on-Graph and Reasoning-on-Graph enhance LLMs‚Äô reasoning abilities by integrating KGs. LLM-based question answering systems employ KGs to boost inference capabilities in specialized domains.\n",
            "\n",
            "## METHODS\n",
            "\n",
            "We introduce an LLM-based customer service question answering system that seamlessly integrates retrieval-augmented generation (RAG) with a knowledge graph (KG). Our system comprises two phases: KG construction phase and question-answering phase. During the KG construction phase, our system constructs a comprehensive knowledge graph from historical customer service issue tickets. It integrates a tree-structured representation of each issue and interlinks them based on relational context. It also generates embedding for each node to facilitate later semantic searching. During the question-answering phase, our method parses consumer queries to identify named entities and intents, then navigates within the KG to identify related sub-graphs for generating answers.\n",
            "---\n",
            "## Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering SIGIR ‚Äô24, July 14‚Äì18, 2024, Washington, DC, USA\n",
            "\n",
            "|Knowledge Graph Construction|Retrieval and Question Answering|\n",
            "|---|---|\n",
            "|Ticket ENT-1744|Ticket ENT-3547|Ticket PORT-133061|CLONE_FROM|Ticket ENT-22970|Question Query: How to reproduce the issue where user saw \"csv upload error in updating user email\" and has major priority that was caused by data issue?|\n",
            "|Entity Detection|Intent Classification|\n",
            "|2 inter-ticket connection|1 intra-ticket connection|\n",
            "|Summary: \"CSV upload error in updating user email\"|Priority: Major|Root Cause: Data Issue|Intent: Steps to Reproduce|\n",
            "| |Embedding-based Retrieval|Filtering|Filtering|Question Intent|\n",
            "|Inter-ticket connections|Graph Database intra-ticket tree representation|\n",
            "|Ticket PORT-133061 \"CSV upload error, updating user email\"|CLONE_FROM|Ticket ENT-22970 \"CSV upload error, updating user email\"|\n",
            "|...|...|...|SIMILAR_TO|HAS_FIELDS|HAS_COMMENTS|\n",
            "|Ticket ENT-1744|HAS_SUMMARY|HTTP POST csv upload error-internal error|...|\n",
            "|Ticket ENT-3547|Learning 'upload csv' option fails|...|\n",
            "|Text-embedding Generation for Node Values|Final Answer: based on the ticket ENT-22970, the steps to reproduce the issue is \"1. Refer to the CSV: https://microsoft.sharepoint.com/xxx 2. Open the Dashboard ID xxxxxxxxx 3. Click on Instances > Profile 4. Search for users from the CSV file and note that there are 2 profiles exist.\"|\n",
            "\n",
            "Legends: issue-tracking ticket, step with step numbers, Vector DB, graph nodes with links, Step with LLM, Graph DB\n",
            "\n",
            "Figure 1: An overview of our proposed retrieval-augmented generation with knowledge graph framework. The left side of this diagram illustrates the knowledge graph construction; the right side shows the retrieval and question answering process.\n",
            "\n",
            "### 3.2 Retrieval and Question Answering\n",
            "\n",
            "#### 3.2.1 Query Entity Identification and Intent Detection.\n",
            "\n",
            "In this step, we extract the named entities P of type Map(N ‚Üí V) and the query intent set I from each user query ùëû. The method involves parsing each query ùëû into a key-value pair, where each key ùëõ, mentioned within the query, corresponds to an element in the graph template T, and the value ùë£ represents the information extracted from the query. Concurrently, the query intents I include the entities mentioned in the graph template T that the query aims to address. We leverage LLM with a suitable prompt in this parsing process. For instance, given the query ùëû = \"How to reproduce the login issue where a user can‚Äôt log in to LinkedIn?\", the extracted entity is P = Map(\"issue summary\" ‚Üí \"login issue\", \"issue description\" ‚Üí \"user can‚Äôt log in to LinkedIn\"), and the intent set is I=Set(\"fix solution\"). This method demonstrates notable flexibility in accommodating varied query formulations by leveraging the LLM‚Äôs extensive understanding and interpretive capabilities.\n",
            "\n",
            "#### 3.2.2 Embedding-based Retrieval of Sub-graphs.\n",
            "\n",
            "Our method extracts pertinent sub-graphs from the knowledge graph, aligned with user-provided specifics such as \"issue description\" and \"issue summary\", as well as user intentions like \"fix solution\". This process consists of two primary steps: EBR-based ticket identification and LLM-driven subgraph extraction.\n",
            "---\n",
            "## SIGIR ‚Äô24, July 14‚Äì18, 2024, Washington, DC, USA\n",
            "\n",
            "Zhentao Xu, et al.\n",
            "\n",
            "the same ticket, we rank and select the top ùêæ ticket tickets. This Table 1: Retrieval Performance method presupposes that the occurrence of multiple query entities is indicative of pertinent links, thus improving retrieval precision.\n",
            "\n",
            "| |MRR|Recall@K|NDCG@K|\n",
            "|---|---|---|---|\n",
            "|K=1|K=3|K=1|K=3|\n",
            "| |Baseline|0.522|0.400|0.640|0.400|0.520|\n",
            "| |Experiment|0.927|0.860|1.000|0.860|0.946|\n",
            "\n",
            "In the LLM-driven subgraph extraction step, the system first rephrases the original user query ùëû to include the retrieved ticket ID; the modified query ùëû ‚Ä≤ is then translated into a graph database language, such as Cypher for Neo4j for question answering.\n",
            "\n",
            "| |BLEU|METEOR|ROUGE|\n",
            "|---|---|---|---|\n",
            "|Baseline|0.057|0.279|0.183|\n",
            "|Experiment|0.377|0.613|0.546|\n",
            "\n",
            "### PRODUCTION USE CASE\n",
            "\n",
            "We deployed our method within LinkedIn‚Äôs customer service team, covering multiple product lines. The team was split randomly into two groups: one used our system, while the other stuck to traditional manual methods. As shown in Table 3, the group using our system achieved significant gains, reducing the median resolution time per issue by 28.6%. This highlights our system‚Äôs effectiveness in enhancing customer service efficiency.\n",
            "\n",
            "|Group|Mean|P50|P90|\n",
            "|---|---|---|---|\n",
            "|Tool Not Used|40 Hours|7 Hours|87 Hours|\n",
            "|Tool Used|15 hours|5 hours|47 hours|\n",
            "\n",
            "Answer Generation. Answers are synthesized by correlating retrieved data from Section 3.2.2 with the initial query. The LLM serves as a decoder to formulate responses to user inquiries given the retrieved information. For robust online serving, if query execution encounters issues, a fallback mechanism reverts to a baseline text-based retrieval method.\n",
            "\n",
            "### EXPERIMENT\n",
            "\n",
            "#### Experiment Design\n",
            "\n",
            "Our evaluation employed a curated \"golden\" dataset comprising typical queries, support tickets, and their authoritative solutions. The control group operated with conventional text-based EBR, while the experimental group applied the methodology outlined in this study. For both groups, we utilized the same LLM, specifically GPT-4 [ 1], and the same embedding model, E5 [17 ]. We measured retrieval efficacy using Mean Reciprocal Rank (MRR), recall@K, and NDCG@K. MRR gauges the average inverse rank of the initial correct response, recall@K determines the likelihood of a relevant item‚Äôs appearance within the top K selections, and NDCG@K appraises the rank quality by considering both position and pertinence of items. For question-answering performance, we juxtaposed the \"golden\" solutions against the generated responses, utilizing metrics such as BLEU [11], ROUGE [9], and METEOR [3] scores.\n",
            "\n",
            "#### Result and Analysis\n",
            "\n",
            "The retrieval and question-answering performances are presented in Table 1 and Table 2, respectively. Across all metrics, our method demonstrates consistent improvements. Notably, it surpasses the baseline by 77.6% in MRR and by 0.32 in BLEU score, substantiating its superior retrieval efficacy and question-answering accuracy.\n",
            "\n",
            "### CONCLUSIONS AND FUTURE WORK\n",
            "\n",
            "In conclusion, our research significantly advances automated question answering systems for customer service. Integrating retrieval augmented generation (RAG) with a knowledge graph (KG) has improved retrieval and answering metrics, and overall service effectiveness. Future work will focus on: developing an automated mechanism for extracting graph templates, enhancing system adaptability; investigating dynamic updates to the knowledge graph based on user queries to improve real-time responsiveness; and exploring the system‚Äôs applicability in other contexts beyond customer service.\n",
            "\n",
            "### COMPANY PORTRAIT\n",
            "\n",
            "About LinkedIn: Founded in 2003, LinkedIn connects the world‚Äôs professionals to make them more productive and successful. With more than 1 billion members worldwide, including executives from every Fortune 500 company, LinkedIn is the world‚Äôs largest professional network. The company has a diversified business model with revenue coming from Talent Solutions, Marketing Solutions, Sales Solutions and Premium Subscriptions products. Headquartered in Silicon Valley, LinkedIn has offices across the globe. Please visit https://www.linkedin.com/company/linkedin/about/ for more information.\n",
            "---\n",
            "## Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering SIGIR ‚Äô24, July 14‚Äì18, 2024, Washington, DC, USA\n",
            "\n",
            "### PRESENTER BIO\n",
            "\n",
            "Zhentao Xu is a Senior Software Engineer at LinkedIn. He received his M.S. in Robotics and B.S. in Electrical Engineering and Computer Science (EECS) from University of Michigan. His research interests lie in large language models and natural language generation.\n",
            "\n",
            "### REFERENCES\n",
            "\n",
            "[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 (2023).\n",
            "[2] Atlassian. 2024. Jira | Issue & Project Tracking Software. https://www.atlassian.com/software/jira Accessed: 2024-01-04.\n",
            "[3] Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for MT evaluation wip improved correlation wip human judgments. In Proceedings of pe acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization. 65‚Äì72.\n",
            "[4] Nikita Bhutani, Xinyi Zheng, Kun Qian, Yunyao Li, and H Jagadish. 2020. Answering complex questions by combining information from curated and extracted knowledge bases. In Proceedings of pe first workshop on natural language interfaces. 1‚Äì10.\n",
            "[5] Antoine Bordes, Jason Weston, and Nicolas Usunier. 2014. Open question answering wip weakly supervised embedding models. In Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014, Nancy, France, September 15-19, 2014. Proceedings, Part I 14. Springer, 165‚Äì180.\n",
            "[6] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).\n",
            "[7] Bowen Jin, Gang Liu, Chi Han, Meng Jiang, Heng Ji, and Jiawei Han. 2023. Large Language Models on Graphs: A Comprehensive Survey. arXiv preprint arXiv:2312.02783 (2023).\n",
            "[8] Patrick Lewis, Epan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems 33 (2020), 9459‚Äì9474.\n",
            "[9] Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out. 74‚Äì81.\n",
            "[10] Linhao Luo, Yuan-Fang Li, Gholamreza Haffari, and Shirui Pan. 2023. Reasoning on graphs: Faipful and interpretable large language model reasoning. arXiv preprint arXiv:2310.01061 (2023).\n",
            "\n",
            "[11] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics. 311‚Äì318.\n",
            "\n",
            "[12] Qdrant Team. 2024. Qdrant - Vector Database. https://qdrant.tech/. Accessed: 2024-01-08.\n",
            "\n",
            "[13] Zhixiao Qi, Yijiong Yu, Meiqi Tu, Junyi Tan, and Yongfeng Huang. 2023. Foodgpt: A large language model in food testing domain with incremental pre-training and knowledge graph prompt. arXiv preprint arXiv:2308.10173 (2023).\n",
            "\n",
            "[14] Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn Mazaitis, Ruslan Salakhutdinov, and William Cohen. 2018. Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Ellen Riloff, David Chiang, Julia Hockenmaier, and Jun‚Äôichi Tsujii (Eds.). Association for Computational Linguistics, Brussels, Belgium, 4231‚Äì4242. https://doi.org/10.18653/v1/D18-1455\n",
            "\n",
            "[15] Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Saizhuo Wang, Chen Lin, Yeyun Gong, Heung-Yeung Shum, and Jian Guo. 2023. Think-on-graph: Deep and responsible reasoning of large language model with knowledge graph. arXiv preprint arXiv:2307.07697 (2023).\n",
            "\n",
            "[16] Christina Unger, Lorenz B√ºhmann, Jens Lehmann, Axel-Cyrille Ngonga Ngomo, Daniel Gerber, and Philipp Cimiano. 2012. Template-based question answering over RDF data. In Proceedings of the 21st international conference on World Wide Web. 639‚Äì648.\n",
            "\n",
            "[17] Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, and Furu Wei. 2022. Text embeddings by weakly-supervised contrastive pre-training. arXiv preprint arXiv:2212.03533 (2022).\n",
            "\n",
            "[18] Yilin Wen, Zifeng Wang, and Jimeng Sun. 2023. Mindmap: Knowledge graph prompting sparks graph of thoughts in large language models. arXiv preprint arXiv:2308.09729 (2023).\n",
            "\n",
            "[19] Kun Xu, Yansong Feng, Songfang Huang, and Dongyan Zhao. 2016. Hybrid question answering over knowledge base and free text. In Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers. 2397‚Äì2407.\n",
            "\n",
            "[20] Linyao Yang, Hongyang Chen, Zhao Li, Xiao Ding, and Xindong Wu. 2023. ChatGPT is not Enough: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling. arXiv preprint arXiv:2306.11489 (2023).\n",
            "\n",
            "[21] Scott Wen-tau Yih, Ming-Wei Chang, Xiaodong He, and Jianfeng Gao. 2015. Semantic parsing via staged query graph generation: Question answering with knowledge base. In Proceedings of the Joint Conference of the 53rd Annual Meeting of the ACL and the 7th International Joint Conference on Natural Language Processing of the AFNLP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ‰ΩøÁî®GPT Parse Markdown Ê™îÊ°à\n",
        "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
        "\n",
        "node_parser = MarkdownElementNodeParser(\n",
        "    llm=OpenAI(model=LLM_MODEL), num_workers=8\n",
        ")\n",
        "nodes = node_parser.get_nodes_from_documents(md_documents)\n",
        "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)\n",
        "display(Markdown( '\\n\\n'.join([ t.text for t in nodes] )))\n"
      ],
      "metadata": {
        "id": "2LRB_lFUsV5h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "form",
        "outputId": "df2d091d-fb0d-4ebc-d761-d54f248e6150"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4it [00:00, 4778.47it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering\n\nZhentao Xu &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Mark Jerome Cruz &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Matthew Guevara\n\nzhexu@linkedin.com &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; marcruz@linkedin.com &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mguevara@linkedin.com\n\nLinkedIn Corporation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LinkedIn Corporation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LinkedIn Corporation\n\nSunnyvale, CA, USA &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Sunnyvale, CA, USA &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Sunnyvale, CA, USA\n\nTie Wang &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Manasi Deshpande &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Xiaofeng Wang\n\ntiewang@linkedin.com &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; madeshpande@linkedin.com &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; xiaofwang@linkedin.com\n\nLinkedIn Corporation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LinkedIn Corporation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LinkedIn Corporation\n\nSunnyvale, CA, USA &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Sunnyvale, CA, USA &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Sunnyvale, CA, USA\n\nZheng Li\n\nzeli@linkedin.com\n\nLinkedIn Corporation\n\nSunnyvale, CA, USA\n\n ABSTRACT\n\nIn customer service technical support, swiftly and accurately retrieving relevant past issues is critical for efficiently resolving customer inquiries. The conventional retrieval methods in retrieval-augmented generation (RAG) for large language models (LLMs) treat a large corpus of past issue tracking tickets as plain text, ignoring the crucial intra-issue structure and inter-issue relations, which limits performance. We introduce a novel customer service question-answering method that amalgamates RAG with a knowledge graph (KG). Our method constructs a KG from historical issues for use in retrieval, retaining the intra-issue structure and inter-issue relations. During the question-answering phase, our method parses consumer queries and retrieves related sub-graphs from the KG to generate answers. This integration of a KG not only improves retrieval accuracy by preserving customer service structure information but also enhances answering quality by mitigating the effects of text segmentation. Empirical assessments on our benchmark datasets, utilizing key retrieval (MRR, Recall@K, NDCG@K) and text generation (BLEU, ROUGE, METEOR) metrics, reveal that our method outperforms the baseline by 77.6% in MRR and by 0.32 in BLEU. Our method has been deployed within LinkedIn‚Äôs customer service team for approximately six months and has reduced the median per-issue resolution time by 28.6%.\n\n CCS CONCEPTS\n\n‚Ä¢ Computing methodologies ‚Üí Information extraction; Natural language generation.\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\n\nSIGIR ‚Äô24, July 14‚Äì18, 2024, Washington, DC, USA\n\n¬© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\n\nCCS CONCEPTS\n\n‚Ä¢ Computing methodologies ‚Üí Information extraction; Natural language generation.\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\n\nSIGIR ‚Äô24, July 14‚Äì18, 2024, Washington, DC, USA\n\n¬© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.\n\nACM ISBN 979-8-4007-0431-4/24/07\n\nhttps://doi.org/10.1145/3626772.3661370\n\n ACM Reference Format:\n\nZhentao Xu, Mark Jerome Cruz, Matthew Guevara, Tie Wang, Manasi Deshpande, Xiaofeng Wang, and Zheng Li. 2024. Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering. In Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ‚Äô24), July 14‚Äì18, 2024, Washington, DC, USA. ACM, New York, NY, USA, 5 pages.\n\nhttps://doi.org/10.1145/3626772.3661370\n\n 1 INTRODUCTION\n\nEffective technical support in customer service underpins product success, directly influencing customer satisfaction and loyalty. Given the frequent similarity of customer inquiries to previously resolved issues, the rapid and accurate retrieval of relevant past instances is crucial for the efficient resolution of such inquiries. Recent advancements in embedding-based retrieval (EBR), large language models (LLMs), and retrieval-augmented generation (RAG) have significantly enhanced retrieval performance and question-answering capabilities for the technical support of customer service. This process typically unfolds in two stages: first, historical issue tickets are treated as plain text, segmented into smaller chunks to accommodate the context length constraints of embedding models; each chunk is then converted into an embedding vector for retrieval. Second, during the question-answering phase, the system retrieves the most relevant chunks and feeds them as contexts for LLMs to generate answers in response to queries. Despite its straightforward approach, this method encounters several limitations:\n\n- Limitation 1 - Compromised Retrieval Accuracy from Ignoring Structures: Issue tracking documents such as Jira possess inherent structure and are interconnected, with references such as \"issue A is related to/copied from/caused\"\n---\n SIGIR ‚Äô24, July 14‚Äì18, 2024, Washington, DC, USA Zhentao Xu, et al.\n\nLimitation 1 - Loss of Intrinsic Relationship: The conventional approach of compressing documents into text chunks leads to the loss of vital information. Our approach parses issue tickets into trees and further connects individual issue tickets to form an interconnected graph, which maintains this intrinsic relationship among entities, achieving high retrieval performance.\n\nLimitation 2 - Reduced Answer Quality from Segmentation: Segmenting extensive issue tickets into fixed-length segments to accommodate the context length constraints of embedding models can result in the disconnection of related content, leading to incomplete answers. Our graph-based parsing method overcomes this by preserving the logical coherence of ticket sections, ensuring the delivery of complete and high-quality responses.\n\n RELATED WORK\n\nQuestion answering (QA) with knowledge graphs (KGs) can be broadly classified into retrieval-based, template-based, and semantic parsing-based methods. Retrieval-based approaches utilize relation extraction or distributed representations to derive answers from KGs, but they face difficulties with questions involving multiple entities. Template-based strategies depend on manually-created templates for encoding complex queries, yet are limited by the scope of available templates. Semantic parsing methods map text to logical forms containing predicates from KGs.\n\nRecent advancements in large language models (LLMs) integration with Knowledge Graphs (KGs) have demonstrated notable progress. For graph-based reasoning, Think-on-Graph and Reasoning-on-Graph enhance LLMs‚Äô reasoning abilities by integrating KGs. LLM-based question answering systems employ KGs to boost inference capabilities in specialized domains.\n\n METHODS\n\nWe introduce an LLM-based customer service question answering system that seamlessly integrates retrieval-augmented generation (RAG) with a knowledge graph (KG). Our system comprises two phases: KG construction phase and question-answering phase. During the KG construction phase, our system constructs a comprehensive knowledge graph from historical customer service issue tickets. It integrates a tree-structured representation of each issue and interlinks them based on relational context.\n\nSemantic parsing methods map text to logical forms containing predicates from KGs.\n\nRecent advancements in large language models (LLMs) integration with Knowledge Graphs (KGs) have demonstrated notable progress. For graph-based reasoning, Think-on-Graph and Reasoning-on-Graph enhance LLMs‚Äô reasoning abilities by integrating KGs. LLM-based question answering systems employ KGs to boost inference capabilities in specialized domains.\n\n METHODS\n\nWe introduce an LLM-based customer service question answering system that seamlessly integrates retrieval-augmented generation (RAG) with a knowledge graph (KG). Our system comprises two phases: KG construction phase and question-answering phase. During the KG construction phase, our system constructs a comprehensive knowledge graph from historical customer service issue tickets. It integrates a tree-structured representation of each issue and interlinks them based on relational context. It also generates embedding for each node to facilitate later semantic searching. During the question-answering phase, our method parses consumer queries to identify named entities and intents, then navigates within the KG to identify related sub-graphs for generating answers.\n---\n Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering SIGIR ‚Äô24, July 14‚Äì18, 2024, Washington, DC, USA\n\nThe table provides information on various tickets related to knowledge graph construction, retrieval, and question answering. It includes details on ticket numbers, connections between tickets, entity detection, intent classification, summary of issues, priorities, root causes, and steps to reproduce specific issues.,\nwith the following table title:\nTickets and Connections Summary,\nwith the following columns:\n- Categories: None\n- Details: None\n\n\nThe table provides information on various tickets related to knowledge graph construction, retrieval, and question answering. It includes details on ticket numbers, connections between tickets, entity detection, intent classification, summary of issues, priorities, root causes, and steps to reproduce specific issues.,\nwith the following table title:\nTickets and Connections Summary,\nwith the following columns:\n- Categories: None\n- Details: None\n\n|Knowledge Graph Construction|Retrieval and Question Answering|\n|---|---|\n|Ticket ENT-1744|Ticket ENT-3547|Ticket PORT-133061|CLONE_FROM|Ticket ENT-22970|Question Query: How to reproduce the issue where user saw \"csv upload error in updating user email\" and has major priority that was caused by data issue?|\n|Entity Detection|Intent Classification|\n|2 inter-ticket connection|1 intra-ticket connection|\n|Summary: \"CSV upload error in updating user email\"|Priority: Major|Root Cause: Data Issue|Intent: Steps to Reproduce|\n| |Embedding-based Retrieval|Filtering|Filtering|Question Intent|\n|Inter-ticket connections|Graph Database intra-ticket tree representation|\n|Ticket PORT-133061 \"CSV upload error, updating user email\"|CLONE_FROM|Ticket ENT-22970 \"CSV upload error, updating user email\"|\n|...|...|...|SIMILAR_TO|HAS_FIELDS|HAS_COMMENTS|\n|Ticket ENT-1744|HAS_SUMMARY|HTTP POST csv upload error-internal error|...|\n|Ticket ENT-3547|Learning 'upload csv' option fails|...|\n|Text-embedding Generation for Node Values|Final Answer: based on the ticket ENT-22970, the steps to reproduce the issue is \"1. Refer to the CSV: https://microsoft.sharepoint.com/xxx 2. Open the Dashboard ID xxxxxxxxx 3. Click on Instances > Profile 4. Search for users from the CSV file and note that there are 2 profiles exist.\"|\n\nLegends: issue-tracking ticket, step with step numbers, Vector DB, graph nodes with links, Step with LLM, Graph DB\n\nFigure 1: An overview of our proposed retrieval-augmented generation with knowledge graph framework. The left side of this diagram illustrates the knowledge graph construction; the right side shows the retrieval and question answering process.\n\n 3.2 Retrieval and Question Answering\n\n 3.2.1 Query Entity Identification and Intent Detection.\n\nIn this step, we extract the named entities P of type Map(N ‚Üí V) and the query intent set I from each user query ùëû. The method involves parsing each query ùëû into a key-value pair, where each key ùëõ, mentioned within the query, corresponds to an element in the graph template T, and the value ùë£ represents the information extracted from the query. Concurrently, the query intents I include the entities mentioned in the graph template T that the query aims to address. We leverage LLM with a suitable prompt in this parsing process. For instance, given the query ùëû = \"How to reproduce the login issue where a user can‚Äôt log in to LinkedIn?\", the extracted entity is P = Map(\"issue summary\" ‚Üí \"login issue\", \"issue description\" ‚Üí \"user can‚Äôt log in to LinkedIn\"), and the intent set is I=Set(\"fix solution\"). This method demonstrates notable flexibility in accommodating varied query formulations by leveraging the LLM‚Äôs extensive understanding and interpretive capabilities.\n\n 3.2.2 Embedding-based Retrieval of Sub-graphs.\n\nOur method extracts pertinent sub-graphs from the knowledge graph, aligned with user-provided specifics such as \"issue description\" and \"issue summary\", as well as user intentions like \"fix solution\". This process consists of two primary steps: EBR-based ticket identification and LLM-driven subgraph extraction.\n---\n SIGIR ‚Äô24, July 14‚Äì18, 2024, Washington, DC, USA\n\nZhentao Xu, et al.\n\nthe same ticket, we rank and select the top ùêæ ticket tickets. This Table 1: Retrieval Performance method presupposes that the occurrence of multiple query entities is indicative of pertinent links, thus improving retrieval precision.\n\nComparison of Baseline and Experiment results for MRR, Recall@K, and NDCG@K at K=1 and K=3,\nwith the following table title:\nBaseline vs. Experiment Results,\nwith the following columns:\n- MRR: Mean Reciprocal Rank (MRR) values for Baseline and Experiment\n- Recall@K: Recall values at K=1 and K=3 for Baseline and Experiment\n- NDCG@K: Normalized Discounted Cumulative Gain (NDCG) values at K=1 and K=3 for Baseline and Experiment\n\n\nComparison of Baseline and Experiment results for MRR, Recall@K, and NDCG@K at K=1 and K=3,\nwith the following table title:\nBaseline vs. Experiment Results,\nwith the following columns:\n- MRR: Mean Reciprocal Rank (MRR) values for Baseline and Experiment\n- Recall@K: Recall values at K=1 and K=3 for Baseline and Experiment\n- NDCG@K: Normalized Discounted Cumulative Gain (NDCG) values at K=1 and K=3 for Baseline and Experiment\n\n| |MRR|Recall@K|NDCG@K|\n|---|---|---|---|\n|K=1|K=3|K=1|K=3|\n| |Baseline|0.522|0.400|0.640|0.400|0.520|\n| |Experiment|0.927|0.860|1.000|0.860|0.946|\n\nIn the LLM-driven subgraph extraction step, the system first rephrases the original user query ùëû to include the retrieved ticket ID; the modified query ùëû ‚Ä≤ is then translated into a graph database language, such as Cypher for Neo4j for question answering.\n\nThis table compares the performance metrics (BLEU, METEOR, ROUGE) between a Baseline and an Experiment.,\nwith the following table title:\nPerformance Metrics Comparison,\nwith the following columns:\n- BLEU: None\n- METEOR: None\n- ROUGE: None\n\n\nThis table compares the performance metrics (BLEU, METEOR, ROUGE) between a Baseline and an Experiment.,\nwith the following table title:\nPerformance Metrics Comparison,\nwith the following columns:\n- BLEU: None\n- METEOR: None\n- ROUGE: None\n\n| |BLEU|METEOR|ROUGE|\n|---|---|---|---|\n|Baseline|0.057|0.279|0.183|\n|Experiment|0.377|0.613|0.546|\n\n\nPRODUCTION USE CASE\n\nWe deployed our method within LinkedIn‚Äôs customer service team, covering multiple product lines. The team was split randomly into two groups: one used our system, while the other stuck to traditional manual methods. As shown in Table 3, the group using our system achieved significant gains, reducing the median resolution time per issue by 28.6%. This highlights our system‚Äôs effectiveness in enhancing customer service efficiency.\n\nThe table compares the time taken for a task when a tool is used versus when the tool is not used.,\nwith the following table title:\nComparison of Task Time with and without Tool,\nwith the following columns:\n- Group: None\n- Mean: None\n- P50: None\n- P90: None\n\n\nThe table compares the time taken for a task when a tool is used versus when the tool is not used.,\nwith the following table title:\nComparison of Task Time with and without Tool,\nwith the following columns:\n- Group: None\n- Mean: None\n- P50: None\n- P90: None\n\n|Group|Mean|P50|P90|\n|---|---|---|---|\n|Tool Not Used|40 Hours|7 Hours|87 Hours|\n|Tool Used|15 hours|5 hours|47 hours|\n\n\nAnswer Generation. Answers are synthesized by correlating retrieved data from Section 3.2.2 with the initial query. The LLM serves as a decoder to formulate responses to user inquiries given the retrieved information. For robust online serving, if query execution encounters issues, a fallback mechanism reverts to a baseline text-based retrieval method.\n\n EXPERIMENT\n\n Experiment Design\n\nOur evaluation employed a curated \"golden\" dataset comprising typical queries, support tickets, and their authoritative solutions. The control group operated with conventional text-based EBR, while the experimental group applied the methodology outlined in this study. For both groups, we utilized the same LLM, specifically GPT-4 [ 1], and the same embedding model, E5 [17 ]. We measured retrieval efficacy using Mean Reciprocal Rank (MRR), recall@K, and NDCG@K. MRR gauges the average inverse rank of the initial correct response, recall@K determines the likelihood of a relevant item‚Äôs appearance within the top K selections, and NDCG@K appraises the rank quality by considering both position and pertinence of items. For question-answering performance, we juxtaposed the \"golden\" solutions against the generated responses, utilizing metrics such as BLEU [11], ROUGE [9], and METEOR [3] scores.\n\n Result and Analysis\n\nThe retrieval and question-answering performances are presented in Table 1 and Table 2, respectively. Across all metrics, our method demonstrates consistent improvements. Notably, it surpasses the baseline by 77.6% in MRR and by 0.32 in BLEU score, substantiating its superior retrieval efficacy and question-answering accuracy.\n\n CONCLUSIONS AND FUTURE WORK\n\nIn conclusion, our research significantly advances automated question answering systems for customer service. Integrating retrieval augmented generation (RAG) with a knowledge graph (KG) has improved retrieval and answering metrics, and overall service effectiveness. Future work will focus on: developing an automated mechanism for extracting graph templates, enhancing system adaptability; investigating dynamic updates to the knowledge graph based on user queries to improve real-time responsiveness; and exploring the system‚Äôs applicability in other contexts beyond customer service.\n\n COMPANY PORTRAIT\n\nAbout LinkedIn: Founded in 2003, LinkedIn connects the world‚Äôs professionals to make them more productive and successful. With more than 1 billion members worldwide, including executives from every Fortune 500 company, LinkedIn is the world‚Äôs largest professional network. The company has a diversified business model with revenue coming from Talent Solutions, Marketing Solutions, Sales Solutions and Premium Subscriptions products. Headquartered in Silicon Valley, LinkedIn has offices across the globe. Please visit https://www.linkedin.com/company/linkedin/about/ for more information.\n---\n Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering SIGIR ‚Äô24, July 14‚Äì18, 2024, Washington, DC, USA\n\n PRESENTER BIO\n\nZhentao Xu is a Senior Software Engineer at LinkedIn. He received his M.S. in Robotics and B.S. in Electrical Engineering and Computer Science (EECS) from University of Michigan. His research interests lie in large language models and natural language generation.\n\n REFERENCES\n\n[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 (2023).\n[2] Atlassian. 2024. Jira | Issue & Project Tracking Software. https://www.atlassian.com/software/jira Accessed: 2024-01-04.\n[3] Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for MT evaluation wip improved correlation wip human judgments. In Proceedings of pe acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization. 65‚Äì72.\n[4] Nikita Bhutani, Xinyi Zheng, Kun Qian, Yunyao Li, and H Jagadish. 2020. Answering complex questions by combining information from curated and extracted knowledge bases. In Proceedings of pe first workshop on natural language interfaces. 1‚Äì10.\n[5] Antoine Bordes, Jason Weston, and Nicolas Usunier. 2014. Open question answering wip weakly supervised embedding models. In Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014, Nancy, France, September 15-19, 2014. Proceedings, Part I 14.\n\n2005. METEOR: An automatic metric for MT evaluation wip improved correlation wip human judgments. In Proceedings of pe acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization. 65‚Äì72.\n[4] Nikita Bhutani, Xinyi Zheng, Kun Qian, Yunyao Li, and H Jagadish. 2020. Answering complex questions by combining information from curated and extracted knowledge bases. In Proceedings of pe first workshop on natural language interfaces. 1‚Äì10.\n[5] Antoine Bordes, Jason Weston, and Nicolas Usunier. 2014. Open question answering wip weakly supervised embedding models. In Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014, Nancy, France, September 15-19, 2014. Proceedings, Part I 14. Springer, 165‚Äì180.\n[6] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).\n[7] Bowen Jin, Gang Liu, Chi Han, Meng Jiang, Heng Ji, and Jiawei Han. 2023. Large Language Models on Graphs: A Comprehensive Survey. arXiv preprint arXiv:2312.02783 (2023).\n[8] Patrick Lewis, Epan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems 33 (2020), 9459‚Äì9474.\n[9] Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out. 74‚Äì81.\n[10] Linhao Luo, Yuan-Fang Li, Gholamreza Haffari, and Shirui Pan. 2023. Reasoning on graphs: Faipful and interpretable large language model reasoning. arXiv preprint arXiv:2310.01061 (2023).\n\n[11] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics. 311‚Äì318.\n\n[12] Qdrant Team. 2024. Qdrant - Vector Database. https://qdrant.tech/. Accessed: 2024-01-08.\n\n[13] Zhixiao Qi, Yijiong Yu, Meiqi Tu, Junyi Tan, and Yongfeng Huang. 2023. Foodgpt: A large language model in food testing domain with incremental pre-training and knowledge graph prompt. arXiv preprint arXiv:2308.10173 (2023).\n\n[14] Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn Mazaitis, Ruslan Salakhutdinov, and William Cohen. 2018. Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Ellen Riloff, David Chiang, Julia Hockenmaier, and Jun‚Äôichi Tsujii (Eds.). Association for Computational Linguistics, Brussels, Belgium, 4231‚Äì4242. https://doi.org/10.18653/v1/D18-1455\n\n[15] Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Saizhuo Wang, Chen Lin, Yeyun Gong, Heung-Yeung Shum, and Jian Guo. 2023. Think-on-graph: Deep and responsible reasoning of large language model with knowledge graph. arXiv preprint arXiv:2307.07697 (2023).\n\n[16] Christina Unger, Lorenz B√ºhmann, Jens Lehmann, Axel-Cyrille Ngonga Ngomo, Daniel Gerber, and Philipp Cimiano. 2012. Template-based question answering over RDF data. In Proceedings of the 21st international conference on World Wide Web. 639‚Äì648.\n\nAssociation for Computational Linguistics, Brussels, Belgium, 4231‚Äì4242. https://doi.org/10.18653/v1/D18-1455\n\n[15] Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Saizhuo Wang, Chen Lin, Yeyun Gong, Heung-Yeung Shum, and Jian Guo. 2023. Think-on-graph: Deep and responsible reasoning of large language model with knowledge graph. arXiv preprint arXiv:2307.07697 (2023).\n\n[16] Christina Unger, Lorenz B√ºhmann, Jens Lehmann, Axel-Cyrille Ngonga Ngomo, Daniel Gerber, and Philipp Cimiano. 2012. Template-based question answering over RDF data. In Proceedings of the 21st international conference on World Wide Web. 639‚Äì648.\n\n[17] Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, and Furu Wei. 2022. Text embeddings by weakly-supervised contrastive pre-training. arXiv preprint arXiv:2212.03533 (2022).\n\n[18] Yilin Wen, Zifeng Wang, and Jimeng Sun. 2023. Mindmap: Knowledge graph prompting sparks graph of thoughts in large language models. arXiv preprint arXiv:2308.09729 (2023).\n\n[19] Kun Xu, Yansong Feng, Songfang Huang, and Dongyan Zhao. 2016. Hybrid question answering over knowledge base and free text. In Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers. 2397‚Äì2407.\n\n[20] Linyao Yang, Hongyang Chen, Zhao Li, Xiao Ding, and Xindong Wu. 2023. ChatGPT is not Enough: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling. arXiv preprint arXiv:2306.11489 (2023).\n\n[21] Scott Wen-tau Yih, Ming-Wei Chang, Xiaodong He, and Jianfeng Gao. 2015. Semantic parsing via staged query graph generation: Question answering with knowledge base. In Proceedings of the Joint Conference of the 53rd Annual Meeting of the ACL and the 7th International Joint Conference on Natural Language Processing of the AFNLP."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ‰ΩøÁî®ChatGPT ÁøªË≠Ø\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    # Defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        ")\n",
        "\n",
        "TRANSLATE_MODEL = \"gpt-3.5-turbo-0125\"  # @param {type:\"string\"}\n",
        "SYSTEM_PROMPT = 'Ë´ã‰Ω†ÊàêÁÇ∫ÊñáÁ´†ÁøªË≠ØÁöÑÂ∞èÂπ´ÊâãÔºåË´ãÂçîÂä©ÁøªË≠Ø‰ª•‰∏ãÊäÄË°ìÊñá‰ª∂Ôºå‰ª•ÁπÅÈ´î‰∏≠ÊñáËº∏Âá∫'  # @param {type:\"string\"}\n",
        "def translate_text(text):\n",
        "  completion = client.chat.completions.create(\n",
        "    model=TRANSLATE_MODEL,\n",
        "    messages=[\n",
        "          {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "          {\"role\": \"user\", \"content\":text},\n",
        "      ]\n",
        "  )\n",
        "  return completion.choices[0].message.content\n",
        "\n",
        "translated_text = []\n",
        "for node in nodes:\n",
        "  translated_text.append(translate_text(node.text))\n",
        "\n",
        "\n",
        "display(Markdown( '\\n\\n'.join([ t for t in translated_text] )))\n"
      ],
      "metadata": {
        "id": "wuMiLfpSs-zw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "form",
        "outputId": "2b8dca0f-ba13-4033-a13f-40113af14b2d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Áü•Ë≠òÂúñË≠úÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÁî®ÊñºÂÆ¢Êà∂ÊúçÂãôÂïèÁ≠î\n\nË®±ÊåØÊø§ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Mark Jerome Cruz &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Matthew Guevara\n\nzhexu@linkedin.com &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; marcruz@linkedin.com &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; mguevara@linkedin.com\n\nLinkedIn Corporation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LinkedIn Corporation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LinkedIn Corporation\n\nÁæéÂúãÂä†Â∑ûËÅñÂ∞ºÁ∂≠Áàæ\n\nTie Wang &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Manasi Deshpande &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Xiaofeng Wang\n\ntiewang@linkedin.com &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; madeshpande@linkedin.com &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; xiaofwang@linkedin.com\n\nLinkedIn Corporation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LinkedIn Corporation &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; LinkedIn Corporation\n\nÁæéÂúãÂä†Â∑ûËÅñÂ∞ºÁ∂≠Áàæ\n\nZheng Li\n\nzeli@linkedin.com\n\nLinkedIn Corporation\n\nÁæéÂúãÂä†Â∑ûËÅñÂ∞ºÁ∂≠Áàæ\n\nÊëòË¶Å\n\nÂú®ÂÆ¢Êà∂ÊúçÂãôÊäÄË°ìÊîØÊè¥‰∏≠ÔºåËøÖÈÄüÂáÜÁ¢∫Âú∞Ê™¢Á¥¢Áõ∏ÈóúÁöÑÈÅéÂæÄÂïèÈ°åÂ∞çÊñºÈ´òÊïàËß£Ê±∫ÂÆ¢Êà∂Êü•Ë©¢Ëá≥ÈóúÈáçË¶Å„ÄÇÂÇ≥Áµ±ÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºàRAGÔºâÊñπÊ≥ïÂ∞çÊñºÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMsÔºâ‰∏≠ÁöÑÂ§ßÂûãÂïèÈ°åËøΩËπ§Á•®ÊìöÂ∞áÂÖ∂‰ΩúÁÇ∫Á¥îÊñáÊú¨ËôïÁêÜÔºåÂøΩÁï•‰∫ÜÈóúÈçµÁöÑÂÖßÈÉ®ÂïèÈ°åÁµêÊßãÂíåÂïèÈ°å‰πãÈñìÁöÑÈóú‰øÇÔºåÈÄôÈôêÂà∂‰∫ÜÊÄßËÉΩ„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÂÆ¢Êà∂ÊúçÂãôÂïèÁ≠îÊñπÊ≥ïÔºåÂ∞áRAGËàáÁü•Ë≠òÂúñË≠úÔºàKGÔºâÁõ∏ÁµêÂêà„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÂæûÊ≠∑Âè≤ÂïèÈ°åÊßãÂª∫Áü•Ë≠òÂúñË≠ú‰ª•Áî®ÊñºÊ™¢Á¥¢Ôºå‰øùÁïô‰∫ÜÂÖßÈÉ®ÂïèÈ°åÁµêÊßãÂíåÂïèÈ°å‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÂú®ÂïèÁ≠îÈöéÊÆµÔºåÊàëÂÄëÁöÑÊñπÊ≥ïËß£ÊûêÊ∂àË≤ªËÄÖÊü•Ë©¢‰∏¶ÂæûÁü•Ë≠òÂúñË≠ú‰∏≠Ê™¢Á¥¢Áõ∏ÈóúÂ≠êÂúñ‰ª•ÁîüÊàêÁ≠îÊ°à„ÄÇÈÄöÈÅéÂ∞áÁü•Ë≠òÂúñË≠úÊï¥ÂêàÂà∞KG‰∏≠Ôºå‰∏çÂÉÖÈÄöÈÅé‰øùÁïôÂÆ¢ÊúçÁµêÊßã‰ø°ÊÅØÊèêÈ´ò‰∫ÜÊ™¢Á¥¢ÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÈÇÑÈÄöÈÅéÊ∏õËºïÊñáÊú¨ÂàáÂâ≤ÁöÑÂΩ±Èüø‰æÜÊèêÈ´ò‰∫ÜÁ≠îÊ°àÁöÑË≥™Èáè„ÄÇÈÄöÈÅéÂú®ÊàëÂÄëÁöÑÂü∫Ê∫ñÊï∏ÊìöÈõÜ‰∏äÈÄ≤Ë°åÂØ¶Ë≠âË©ï‰º∞ÔºåÂà©Áî®ÈóúÈçµÊ™¢Á¥¢ÔºàMRR„ÄÅRecall@K„ÄÅNDCG@KÔºâÂíåÊñáÊú¨ÁîüÊàêÔºàBLEU„ÄÅROUGE„ÄÅMETEORÔºâÊåáÊ®ôÔºåÁµêÊûúÈ°ØÁ§∫ÊàëÂÄëÁöÑÊñπÊ≥ïÂú®MRRÊñπÈù¢Ë∂ÖË∂äÂü∫Á∑ö77.6%ÔºåÂú®BLEUÊñπÈù¢Ë∂ÖË∂äÂü∫Á∑ö0.32„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÂ∑≤Âú®LinkedInÁöÑÂÆ¢Êà∂ÊúçÂãôÂúòÈöä‰∏≠‰ΩøÁî®Á¥ÑÂÖ≠ÂÄãÊúàÔºåÂ∞áÊØèÂÄãÂïèÈ°åÁöÑËß£Ê±∫‰∏≠‰ΩçÊï∏ÊôÇÈñìÈôç‰Ωé‰∫Ü28.6%„ÄÇ\n\nCCSÊ¶ÇÂøµ\n\n‚Ä¢ Ë®àÁÆóÊñπÊ≥ïË´ñ ‚Üí ‰ø°ÊÅØÊèêÂèñÔºõËá™ÁÑ∂Ë™ûË®ÄÁîüÊàê„ÄÇ\n\nCCSÊ¶ÇÂøµ\n\n‚Ä¢ Ë®àÁÆóÊñπÊ≥ïË´ñ ‚Üí ‰ø°ÊÅØÊèêÂèñÔºõËá™ÁÑ∂Ë™ûË®ÄÁîüÊàê„ÄÇ\n\nÊú™Á∂ìË®±ÂèØÔºå‰ªª‰ΩïÂÄã‰∫∫ÊàñÊïôÂÆ§ÂùáÂèØË£Ω‰ΩúÊ≠§‰ΩúÂìÅÁöÑÊï∏Á¢ºÊàñÂç∞Âà∑Êã∑Ë≤ùÔºåÂâçÊèêÊòØ‰∏çÂæóÂõ†Ê≠§ÁâüÂà©ÊàñÂïÜÊ•≠ÂÑ™Âã¢ÔºåÊã∑Ë≤ùÂøÖÈ†àË®ªÊòéÊ≠§ÈÄöÁü•ÂíåÁ¨¨‰∏ÄÈ†ÅÁöÑÂÆåÊï¥ÂºïÁî®„ÄÇÊ≠§‰ΩúÂìÅ‰∏≠ÂÖ∂‰ªñ‰ΩúËÄÖÊìÅÊúâÁâàÊ¨äÁöÑÈÉ®ÂàÜÔºåÂøÖÈ†à‰∫à‰ª•Â∞äÈáç„ÄÇÂÖÅË®±Â∏∂Êúâ‰ø°Áî®ÊëòË¶Å„ÄÇÊú™Á∂ìÊéàÊ¨äÊàñ‰ªòË≤ªÔºå‰∏çÂæóË§áË£Ω„ÄÅÂÜçÂá∫Áâà„ÄÅÂºµË≤ºÂú®‰º∫ÊúçÂô®‰∏äÊàñÈáçÊñ∞ÂàÜÁôºÂà∞Ê∏ÖÂñÆ‰∏≠„ÄÇË´ãÂêë permissions@acm.org Ë´ãÊ±ÇË®±ÂèØ„ÄÇ\n\nSIGIR ‚Äô24Ôºå2024Âπ¥7Êúà14Êó•Ëá≥18Êó•ÔºåÁæéÂúãËèØÁõõÈ†ìÁâπÂçÄ\n\n¬© 2024 ÁâàÊ¨äÊ≠∏ÊìÅÊúâËÄÖ/‰ΩúËÄÖÊåÅÊúâ„ÄÇÁôºË°®Ê¨äÂà©Ë®±ÂèØÁµ¶ACM„ÄÇ\n\nACM ISBN 979-8-4007-0431-4/24/07\n\nhttps://doi.org/10.1145/3626772.3661370\n\n ACM ÂèÉËÄÉÊ†ºÂºèÔºö\n\nZhentao Xu, Mark Jerome Cruz, Matthew Guevara, Tie Wang, Manasi Deshpande, Xiaofeng Wang Âíå Zheng Li. 2024. ‰ΩøÁî®Áü•Ë≠òÂúñÂíåÊ™¢Á¥¢Â¢ûÂº∑ÁöÑÁîüÊàêÈÄ≤Ë°åÂÆ¢Êà∂ÊúçÂãôÂïèÁ≠î. Âú®Á¨¨47Â±ÜÂúãÈöõACM SIGIR‰ø°ÊÅØÊ™¢Á¥¢Á†îÁ©∂ËàáÈñãÁôºÂ§ßÊúÉ (SIGIR ‚Äô24) ÊúÉË≠∞Ë´ñÊñáÈõÜ‰∏≠Ôºå2024Âπ¥7Êúà14Êó•Ëá≥18Êó•ÔºåÁæéÂúãËèØÁõõÈ†ìÁâπÂçÄ„ÄÇACMÔºåÁæéÂúãÁ¥êÁ¥ÑÔºå5È†Å„ÄÇ\n\nhttps://doi.org/10.1145/3626772.3661370\n\n 1 ÂºïË®Ä\n\nÂÆ¢Êà∂ÊúçÂãô‰∏≠ÊúâÊïàÁöÑÊäÄË°ìÊîØÊè¥ÊòØÁî¢ÂìÅÊàêÂäüÁöÑÂü∫Á§éÔºåÁõ¥Êé•ÂΩ±ÈüøÂÆ¢Êà∂ÊªøÊÑèÂ∫¶ÂíåÂø†Ë™†Â∫¶„ÄÇËÄÉÊÖÆÂà∞ÂÆ¢Êà∂Ë©¢ÂïèÈÄöÂ∏∏ËàáÂÖàÂâçËß£Ê±∫ÁöÑÂïèÈ°åÁõ∏‰ººÔºåËøÖÈÄü‰∏îÊ∫ñÁ¢∫Âú∞Ê™¢Á¥¢Áõ∏ÈóúÁöÑÈÅéÂéªÂØ¶‰æãÂ∞çÊñºÈ´òÊïàËß£Ê±∫Ê≠§È°ûÂïèÈ°åËá≥ÈóúÈáçË¶Å„ÄÇÊúÄËøëÂú®Âü∫ÊñºÂµåÂÖ•ÁöÑÊ™¢Á¥¢ÔºàEBRÔºâ„ÄÅÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMsÔºâÂíåÊ™¢Á¥¢Â¢ûÂº∑ÁöÑÁîüÊàêÔºàRAGÔºâÊñπÈù¢ÁöÑÈÄ≤Â±ïÈ°ØËëóÊèêÂçá‰∫ÜÊäÄË°ìÊîØÊè¥ÂÆ¢Êà∂ÊúçÂãôÁöÑÊ™¢Á¥¢ÊÄßËÉΩÂíåÂïèÁ≠îËÉΩÂäõ„ÄÇÈÄô‰∏ÄÈÅéÁ®ãÈÄöÂ∏∏ÂàÜÁÇ∫ÂÖ©ÂÄãÈöéÊÆµÔºöÈ¶ñÂÖàÔºåÂ∞áÊ≠∑Âè≤ÂïèÈ°åÂ∑•ÂñÆË¶ñÁÇ∫Á¥îÊñáÊú¨ÔºåÂàÜÊÆµÁÇ∫ËºÉÂ∞èÁöÑÂ°ä‰ª•ÂÆπÁ¥çÂµåÂÖ•Ê®°ÂûãÁöÑ‰∏ä‰∏ãÊñáÈï∑Â∫¶Á¥ÑÊùüÔºõÁÑ∂ÂæåÂ∞áÊØèÂÄãÂ°äËΩâÊèõÁÇ∫‰∏ÄÂÄãÂµåÂÖ•ÂêëÈáè‰ª•ÈÄ≤Ë°åÊ™¢Á¥¢„ÄÇÂÖ∂Ê¨°ÔºåÂú®ÂïèÁ≠îÈöéÊÆµÔºåÁ≥ªÁµ±Ê™¢Á¥¢ÊúÄÁõ∏ÈóúÁöÑÂ°ä‰∏¶Â∞áÂÆÉÂÄë‰ΩúÁÇ∫‰∏ä‰∏ãÊñáÊèê‰æõÁµ¶LLMsÔºå‰ª•Ê†πÊìöÊü•Ë©¢Áî¢ÁîüÁ≠îÊ°à„ÄÇÂÑòÁÆ°ÈÄôÁ®ÆÊñπÊ≥ïÁúã‰ººÁ∞°ÂñÆÔºå‰ΩÜÈÅáÂà∞‰∫ÜÂπæÂÄãÈôêÂà∂Ôºö\n\n- ÈôêÂà∂1 - ÂæûÂøΩÁï•ÁµêÊßã‰∏≠ÁäßÁâ≤Ê™¢Á¥¢Ê∫ñÁ¢∫ÊÄßÔºöÂïèÈ°åËøΩË∏™ÊñáÊ™îÂ¶ÇJiraÂÖ∑ÊúâÂõ∫ÊúâÁµêÊßã‰∏îÁõ∏‰∫íÈóúËÅØÔºåÂåÖÊã¨‚ÄúÂïèÈ°åAËàá...ÊúâÈóú/Âæ©Âà∂Ëá™/Â∞éËá¥‚Äù\n\n---\n SIGIR ‚Äô24Ôºå2024Âπ¥7Êúà14Êó•Ëá≥18Êó•ÔºåÁæéÂúãËèØÁõõÈ†ìÁâπÂçÄÔºåZhentao XuÁ≠â„ÄÇ\n\nÈôêÂà∂1 - Âõ†ÂàÜÂâ≤ËÄåÂ§±ÂéªÂÖßÂú®Èóú‰øÇÔºöÂ∞áÊñáÊ™îÂ£ìÁ∏ÆÁÇ∫ÊñáÊú¨Â°äÁöÑÂÇ≥Áµ±ÊñπÊ≥ïÊúÉÂ∞éËá¥ÈáçË¶Å‰ø°ÊÅØÁöÑ‰∏üÂ§±„ÄÇÊàëÂÄëÁöÑÊñπÊ≥ïÂ∞áÂïèÈ°åÂ∑•ÂñÆËß£ÊûêÁÇ∫Ê®πÁãÄÁµêÊßãÔºå‰∏¶ÈÄ≤‰∏ÄÊ≠•ÈÄ£Êé•ÂñÆÂÄãÂïèÈ°åÂ∑•ÂñÆ‰ª•ÂΩ¢Êàê‰∏ÄÂÄãÁõ∏‰∫íÈóúËÅØÁöÑÂúñÔºå‰øùÊåÅÂØ¶È´î‰πãÈñìÁöÑÂÖßÂú®Èóú‰øÇÔºåÂæûËÄåÂØ¶ÁèæÈ´òÊïàÁöÑÊ™¢Á¥¢ÊÄßËÉΩ„ÄÇ\n\nÈôêÂà∂2 - Âõ†ÂàÜÂâ≤Â∞éËá¥Á≠îÊ°àË≥™ÈáèÈôç‰ΩéÔºöÂ∞áÂª£Ê≥õÁöÑÂïèÈ°åÂ∑•ÂñÆÂàÜÂâ≤ÁÇ∫Âõ∫ÂÆöÈï∑Â∫¶ÁöÑÊÆµËêΩ‰ª•ÊªøË∂≥ÂµåÂÖ•Ê®°ÂûãÁöÑ‰∏ä‰∏ãÊñáÈï∑Â∫¶Á¥ÑÊùüÂèØËÉΩÂ∞éËá¥Áõ∏ÈóúÂÖßÂÆπÁöÑÂàÜÈõ¢ÔºåÂ∞éËá¥Á≠îÊ°à‰∏çÂÆåÊï¥„ÄÇÊàëÂÄëÂü∫ÊñºÂúñÁöÑËß£ÊûêÊñπÊ≥ïÈÄöÈÅé‰øùÁïôÁ•®ÂãôÈÉ®ÂàÜÁöÑÈÇèËºØ‰∏ÄËá¥ÊÄß‰æÜÂÖãÊúçÈÄô‰∏ÄÂïèÈ°åÔºåÁ¢∫‰øùÊèê‰æõÂÆåÊï¥ÂíåÈ´òË≥™ÈáèÁöÑÁ≠îÊ°à„ÄÇ\n\n Áõ∏ÈóúÂ∑•‰Ωú\n\nÂü∫ÊñºÁü•Ë≠òÂúñÔºàKGsÔºâÁöÑÂïèÁ≠îÔºàQAÔºâÂèØ‰ª•Âª£Ê≥õÂàÜÁÇ∫Ê™¢Á¥¢Âºè„ÄÅÂü∫ÊñºÊ®°ÊùøÂíåÂü∫ÊñºË™ûÁæ©Ëß£ÊûêÁöÑÊñπÊ≥ï„ÄÇÊ™¢Á¥¢ÂºèÊñπÊ≥ïÂà©Áî®Èóú‰øÇÊèêÂèñÊàñÂàÜ‰ΩàÂºèË°®Á§∫‰æÜÂæûKGs‰∏≠Áî¢ÁîüÁ≠îÊ°àÔºå‰ΩÜÂú®Ê∂âÂèäÂ§öÂÄãÂØ¶È´îÁöÑÂïèÈ°å‰∏äÂ≠òÂú®Âõ∞Èõ£„ÄÇÂü∫ÊñºÊ®°ÊùøÁöÑÁ≠ñÁï•‰æùË≥¥ÊñºÊâãÂãïÂâµÂª∫ÁöÑÊ®°Êùø‰æÜÁ∑®Á¢ºË§áÈõúÊü•Ë©¢Ôºå‰ΩÜÂèóÂà∞ÂèØÁî®Ê®°ÊùøÁØÑÂúçÁöÑÈôêÂà∂„ÄÇË™ûÁæ©Ëß£ÊûêÊñπÊ≥ïÂ∞áÊñáÊú¨Êò†Â∞ÑÂà∞ÂåÖÂê´‰æÜËá™KGsÁöÑË¨ÇË©ûÁöÑÈÇèËºØÂΩ¢Âºè„ÄÇ\n\nÊúÄËøëÂú®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMsÔºâËàáÁü•Ë≠òÂúñÔºàKGsÔºâÈõÜÊàêÊñπÈù¢ÂèñÂæó‰∫ÜÈ°ØËëóÈÄ≤Â±ï„ÄÇÈáùÂ∞çÂúñÂΩ¢ÂºèÁöÑÊé®ÁêÜÔºåThink-on-GraphÂíåReasoning-on-GraphÈÄöÈÅéÊï¥ÂêàKGsÂ¢ûÂº∑‰∫ÜLLMsÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÂü∫ÊñºLLMsÁöÑÂïèÁ≠îÁ≥ªÁµ±Âà©Áî®KGsÊèêÂçá‰∫ÜÂ∞àÊ•≠È†òÂüü‰∏≠ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ\n\n ÊñπÊ≥ï\n\nÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÂü∫ÊñºLLMÁöÑÂÆ¢Êà∂ÊúçÂãôÂïèÁ≠îÁ≥ªÁµ±ÔºåË©≤Á≥ªÁµ±ÁÑ°Á∏´ÈõÜÊàê‰∫ÜÊ™¢Á¥¢Â¢ûÂº∑ÁöÑÁîüÊàêÔºàRAGÔºâÂíåÁü•Ë≠òÂúñÔºàKGÔºâ„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±ÂåÖÊã¨ÂÖ©ÂÄãÈöéÊÆµÔºöÁü•Ë≠òÂúñÊßãÂª∫ÈöéÊÆµÂíåÂïèÁ≠îÈöéÊÆµ„ÄÇÂú®Áü•Ë≠òÂúñÊßãÂª∫ÈöéÊÆµÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±ÂæûÊ≠∑Âè≤ÂÆ¢Êà∂ÊúçÂãôÂïèÈ°åÂ∑•ÂñÆ‰∏≠ÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÁü•Ë≠òÂúñ„ÄÇÂÆÉ‰ΩøÁî®ÊØèÂÄãÂïèÈ°åÁöÑÊ®πÁãÄÁµêÊßãÂåñË°®Á§∫Ôºå‰∏¶Ê†πÊìöÈóúËÅØ‰∏ä‰∏ãÊñáÂ∞áÂÆÉÂÄëÈÄ≤Ë°å‰∫íÈÄ£„ÄÇ\n\nË™ûÁæ©ÂàÜÊûêÊñπÊ≥ïÂ∞áÊñáÊú¨Â∞çÊáâÂà∞ÂåÖÂê´Áü•Ë≠òÂúñË≠ú‰∏≠Ë¨ÇË©ûÁöÑÈÇèËºØÂΩ¢Âºè„ÄÇ\n\nÊúÄËøëÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMsÔºâËàáÁü•Ë≠òÂúñË≠úÔºàKGsÔºâÁõ∏ÁµêÂêàÁöÑÂÖàÈÄ≤ÁôºÂ±ïÂ±ïÁ§∫‰∫ÜÈ°ØËëóÈÄ≤Ê≠•„ÄÇÂ∞çÊñºÂü∫ÊñºÂúñË≠úÁöÑÊé®ÁêÜÔºå„ÄåThink-on-Graph„ÄçÂíå„ÄåReasoning-on-Graph„ÄçÈÄöÈÅéÊï¥ÂêàÁü•Ë≠òÂúñË≠ú‰æÜÂ¢ûÂº∑LLMsÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇÂü∫ÊñºLLMsÁöÑÂïèÁ≠îÁ≥ªÁµ±Âà©Áî®Áü•Ë≠òÂúñË≠ú‰æÜÊèêÂçáÂú®Â∞àÈñÄÈ†òÂüü‰∏≠ÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ\n\nÊñπÊ≥ï\n\nÊàëÂÄë‰ªãÁ¥π‰∏ÄÂÄãÂü∫ÊñºLLMsÁöÑÂÆ¢Êà∂ÊúçÂãôÂïèÁ≠îÁ≥ªÁµ±ÔºåË©≤Á≥ªÁµ±ÈÄöÈÅéÁÑ°Á∏´ÈõÜÊàêÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºàRAGÔºâÂíåÁü•Ë≠òÂúñË≠úÔºàKGÔºâ„ÄÇÊàëÂÄëÁöÑÁ≥ªÁµ±Áî±ÂÖ©ÂÄãÈöéÊÆµÁµÑÊàêÔºöÁü•Ë≠òÂúñË≠úÊßãÂª∫ÈöéÊÆµÂíåÂïèÁ≠îÈöéÊÆµ„ÄÇÂú®Áü•Ë≠òÂúñË≠úÊßãÂª∫ÈöéÊÆµÔºåÊàëÂÄëÁöÑÁ≥ªÁµ±ÂæûÊ≠∑Âè≤ÂÆ¢Êà∂ÊúçÂãôÂïèÈ°åÂ∑•ÂñÆ‰∏≠ÊßãÂª∫‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÁü•Ë≠òÂúñË≠ú„ÄÇÂÆÉÂü∫ÊñºÈóú‰øÇ‰∏ä‰∏ãÊñáÂ∞áÊØèÂÄãÂïèÈ°åÊßãÂª∫ÁÇ∫Ê®πÁãÄÁµêÊßãË°®Á§∫Ôºå‰∏¶‰∫íÁõ∏ÈèàÊé•„ÄÇÂÆÉÈÇÑÁÇ∫ÊØèÂÄãÁØÄÈªûÁîüÊàêÂµåÂÖ•‰ª•Êñπ‰æøÂæåÁ∫åÁöÑË™ûÁæ©ÊêúÁ¥¢„ÄÇÂú®ÂïèÁ≠îÈöéÊÆµÔºåÊàëÂÄëÁöÑÊñπÊ≥ïËß£ÊûêÊ∂àË≤ªËÄÖÁöÑÊü•Ë©¢‰ª•Ë≠òÂà•ÂëΩÂêçÂØ¶È´îÂíåÊÑèÂúñÔºåÁÑ∂ÂæåÂú®Áü•Ë≠òÂúñË≠ú‰∏≠Â∞ãÊâæÁõ∏ÈóúÂ≠êÂúñÁî®ÊñºÁîüÊàêÁ≠îÊ°à„ÄÇ\n\nÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÁµêÂêàÁü•Ë≠òÂúñË≠úÁöÑÂÆ¢Êà∂ÊúçÂãôÂïèÁ≠î SIGIR '24Ôºå2024Âπ¥7Êúà14-18Êó•ÔºåÁæéÂúãËèØÁõõÈ†ìÁâπÂçÄ„ÄÇ\n\nË©≤Ë°®Ê†ºÊèê‰æõ‰∫ÜËàáÁü•Ë≠òÂúñË≠úÊßãÂª∫„ÄÅÊ™¢Á¥¢ÂíåÂïèÁ≠îÁõ∏ÈóúÁöÑÂêÑÁ®ÆÁ•®Ë≠â‰ø°ÊÅØ„ÄÇÂÆÉÂåÖÊã¨Á•®Ë≠âÁ∑®Ëôü„ÄÅÁ•®Ë≠â‰πãÈñìÁöÑÈÄ£Êé•„ÄÅÂØ¶È´îÊ™¢Ê∏¨„ÄÅÊÑèÂúñÂàÜÈ°û„ÄÅÂïèÈ°åÁ∏ΩÁµê„ÄÅÂÑ™ÂÖàÁ¥ö„ÄÅÊ†πÊú¨ÂéüÂõ†‰ª•ÂèäÂÜçÁèæÁâπÂÆöÂïèÈ°åÁöÑÊ≠•È©ü„ÄÇ\n\nË°®Ê†ºÊ®ôÈ°åÂ¶Ç‰∏ãÔºö\nÁ•®Ë≠âËàáÈÄ£Êé•ÊëòË¶Å\n\nË°®Ê†ºÂåÖÂê´‰ª•‰∏ãÂàóÔºö\n- È°ûÂà•ÔºöÁÑ°\n- Ë©≥Á¥∞‰ø°ÊÅØÔºöÁÑ°\n\nÁü•Ë≠òÂúñË≠úÂª∫Êßã„ÄÅÊ™¢Á¥¢ÂíåÂïèÁ≠îÁõ∏ÈóúÁöÑÂêÑÁ®ÆÂïèÈ°åÁöÑÁ•®Ë≠â‰ø°ÊÅØÂ¶Ç‰∏ãË°®ÊâÄÁ§∫„ÄÇÂÆÉÂåÖÊã¨ÊúâÈóúÁ•®Ë≠âÁ∑®Ëôü„ÄÅÁ•®Ë≠â‰πãÈñìÁöÑÈóúËÅØ„ÄÅÂØ¶È´îÊ™¢Ê∏¨„ÄÅÊÑèÂúñÂàÜÈ°û„ÄÅÂïèÈ°åÊëòË¶Å„ÄÅÂÑ™ÂÖàÈ†ÜÂ∫è„ÄÅÊ†πÊú¨ÂéüÂõ†‰ª•ÂèäÈáçÁèæÁâπÂÆöÂïèÈ°åÁöÑÊ≠•È©üÁöÑË©≥Á¥∞Ë≥áË®ä„ÄÇ,\n\n‰ª•‰∏ãÊòØË°®ÁöÑÊ®ôÈ°å:\nÁ•®Ë≠âËàáÈóúËÅØÊëòË¶Å\n‰ª•‰∏ãÊòØË°®ÁöÑÊ¨Ñ‰Ωç:\n- ÂàÜÈ°ûÔºöÁÑ°\n- Ë©≥Á¥∞Ë≥áÊñôÔºöÁÑ°\n\n|Áü•Ë≠òÂúñË≠úÂª∫Êßã|Ê™¢Á¥¢ÂíåÂïèÁ≠î|\n|---|---|\n|Á•®Ë≠â ENT-1744|Á•®Ë≠â ENT-3547|Á•®Ë≠â PORT-133061|Âæû CLONE_FROM|Á•®Ë≠â ENT-22970|ÂïèÈ°åÊü•Ë©¢ÔºöÂ¶Ç‰ΩïÈáçÁèæ‰ΩøÁî®ËÄÖÁúãÂà∞ÁöÑ„ÄåÂú®Êõ¥Êñ∞‰ΩøÁî®ËÄÖÈõªÂ≠êÈÉµ‰ª∂ÊôÇÁôºÁîücsv‰∏äÂÇ≥ÈåØË™§„ÄçÂïèÈ°åÔºå‰∏¶‰∏îÊúâÈáçË¶ÅÂÑ™ÂÖàÈ†ÜÂ∫èÔºåÈÄôÊòØÁî±Êï∏ÊìöÂïèÈ°åÂºïËµ∑ÁöÑÔºü|\n|ÂØ¶È´îÊ™¢Ê∏¨|ÊÑèÂúñÂàÜÈ°û|\n|2 ÂÄãÁ•®Ë≠â‰πãÈñìÁöÑÈóúËÅØ|1 ÂÄãÁ•®Ë≠âÂÖßÁöÑÈóúËÅØ|\n|ÊëòË¶ÅÔºö„ÄåÂú®Êõ¥Êñ∞‰ΩøÁî®ËÄÖÈõªÂ≠êÈÉµ‰ª∂ÊôÇÁôºÁîüCSV‰∏äÂÇ≥ÈåØË™§„Äç|ÂÑ™ÂÖàÈ†ÜÂ∫èÔºöÈáçË¶Å|Ê†πÊú¨ÂéüÂõ†ÔºöÊï∏ÊìöÂïèÈ°å|ÊÑèÂúñÔºöÈáçÁèæÊ≠•È©ü|\n| |Âü∫ÊñºÂµåÂÖ•ÁöÑÊ™¢Á¥¢|ÈÅéÊøæ|ÈÅéÊøæ|ÂïèÈ°åÊÑèÂúñ|\n|Á•®Ë≠â PORT-133061„ÄåCSV‰∏äÂÇ≥ÈåØË™§ÔºåÊõ¥Êñ∞‰ΩøÁî®ËÄÖÈõªÂ≠êÈÉµ‰ª∂„Äç|Âæû CLONE_FROM|Á•®Ë≠â ENT-22970„ÄåCSV‰∏äÂÇ≥ÈåØË™§ÔºåÊõ¥Êñ∞‰ΩøÁî®ËÄÖÈõªÂ≠êÈÉµ‰ª∂„Äç|\n|...|...|...|Áõ∏‰ººÊñº|ÊúâÊ¨Ñ‰Ωç|ÊúâË©ïË´ñ|\n|Á•®Ë≠â ENT-1744|ÊúâÊëòË¶Å|HTTP POST csv‰∏äÂÇ≥ÈåØË™§-ÂÖßÈÉ®ÈåØË™§|...|\n|Á•®Ë≠â ENT-3547|Â≠∏Áøí'‰∏äÂÇ≥csv'ÈÅ∏È†ÖÂ§±Êïó|...|\n|Áî®ÊñºÁØÄÈªûÂÄºÁöÑÊñáÊú¨ÂµåÂÖ•ÁîüÊàê|ÊúÄÁµÇÁ≠îÊ°àÔºöÊ†πÊìöÁ•®Ë≠â ENT-22970ÔºåÈáçÁèæÂïèÈ°åÁöÑÊ≠•È©üÁÇ∫„Äå1. ÂèÉËÄÉCSVÔºöhttps://microsoft.sharepoint.com/xxx 2. ÊâìÈñãÂÑÄË°®ÊùøID xxxxxxxxx 3. ÈªûÊìä‚ÄúÂØ¶‰æã‚Äù > ‚ÄúÊ™îÊ°à‚Äù 4. ÂæûCSVÊñáÊ™î‰∏≠ÊêúÁ¥¢Áî®Êà∂‰∏¶Ê≥®ÊÑèÂà∞Êúâ 2 ÂÄãÊ™îÊ°àÂ≠òÂú®„ÄÇ„Äç|\n\nÂÇ≥Ë™™ÔºöÂïèÈ°åËøΩË∏™Â∑•ÂñÆ„ÄÅÊúâÊ≠•È©üËôüÁ¢ºÁöÑÊ≠•È©ü„ÄÅÂêëÈáèË≥áÊñôÂ∫´„ÄÅÂÖ∑ÊúâÈÄ£ÁµêÁöÑÂúñÂΩ¢ÁØÄÈªû„ÄÅÂ∏∂ÊúâLLMÁöÑÊ≠•È©ü„ÄÅÂúñÂΩ¢Ë≥áÊñôÂ∫´\n\nÂúñ1ÔºöÊàëÂÄëÊèêÂá∫ÁöÑÁü•Ë≠òÂúñÂΩ¢Ê°ÜÊû∂Ê™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÁöÑÊ¶ÇËø∞„ÄÇË©≤ÂúñÁöÑÂ∑¶ÂÅ¥È°ØÁ§∫Áü•Ë≠òÂúñÂΩ¢ÊßãÂª∫ÔºåÂè≥ÂÅ¥È°ØÁ§∫Ê™¢Á¥¢ÂíåÂïèÁ≠îÈÅéÁ®ã„ÄÇ\n\n3.2 Ê™¢Á¥¢ÂíåÂïèÁ≠î\n\n3.2.1 Êü•Ë©¢ÂØ¶È´îË≠òÂà•ÂíåÊÑèÂúñÊ™¢Ê∏¨„ÄÇ\n\nÂú®ÈÄô‰∏ÄÊ≠•È©ü‰∏≠ÔºåÊàëÂÄëÂæûÊØèÂÄãÁî®Êà∂Êü•Ë©¢ùëû‰∏≠ÊèêÂèñÈ°ûÂûãÁÇ∫Map(N ‚Üí V)ÁöÑÂëΩÂêçÂØ¶È´îPÂíåÊü•Ë©¢ÊÑèÂúñÈõÜI„ÄÇË©≤ÊñπÊ≥ïÊ∂âÂèäÂ∞áÊØèÂÄãÊü•Ë©¢ùëûËß£ÊûêÁÇ∫ÈçµÂÄºÂ∞çÔºåÂÖ∂‰∏≠Âú®Êü•Ë©¢‰∏≠ÊèêÂà∞ÁöÑÊØèÂÄãÈçµùëõÂ∞çÊáâÊñºÂúñÂΩ¢Ê®°ÊùøT‰∏≠ÁöÑ‰∏ÄÂÄãÂÖÉÁ¥†ÔºåÂÄºùë£‰ª£Ë°®ÂæûÊü•Ë©¢‰∏≠ÊèêÂèñÁöÑ‰ø°ÊÅØ„ÄÇËàáÊ≠§ÂêåÊôÇÔºåÊü•Ë©¢ÊÑèÂúñIÂåÖÊã¨Âú®ÂúñÂΩ¢Ê®°ÊùøT‰∏≠ÊèêÂà∞ÁöÑÊü•Ë©¢Êó®Âú®Ëß£Ê±∫ÁöÑÂØ¶È´î„ÄÇÊàëÂÄëÂú®ÈÄô‰∏ÄËß£ÊûêÈÅéÁ®ã‰∏≠Âà©Áî®LLMÂíåÂêàÈÅ©ÁöÑÊèêÁ§∫„ÄÇ‰æãÂ¶ÇÔºåÂ∞çÊñºÊü•Ë©¢ùëû = \"Â¶Ç‰ΩïÈáçÁèæÁî®Êà∂ÁÑ°Ê≥ïÁôªÈåÑÂà∞LinkedInÁöÑÁôªÈåÑÂïèÈ°åÔºü\"ÔºåÊèêÂèñÁöÑÂØ¶È´îÁÇ∫P = Map(\"ÂïèÈ°åÊëòË¶Å\" ‚Üí \"ÁôªÈåÑÂïèÈ°å\"Ôºå \"ÂïèÈ°åÊèèËø∞\" ‚Üí \"Áî®Êà∂ÁÑ°Ê≥ïÁôªÈåÑÂà∞LinkedIn\" )ÔºåÊÑèÂúñÈõÜÂêàÁÇ∫I=Set(\"‰øÆÂæ©Ëß£Ê±∫ÊñπÊ°à\")„ÄÇË©≤ÊñπÊ≥ïÂ±ïÁ§∫‰∫ÜÈÄöÈÅéÂà©Áî®LLMÂª£Ê≥õÁöÑÁêÜËß£ÂíåËß£ÈáãËÉΩÂäõÔºåÈÅ©ÊáâÂêÑÁ®ÆÊü•Ë©¢ÂΩ¢ÂºèÁöÑÈ°ØËëóÈùàÊ¥ªÊÄß„ÄÇ\n\n3.2.2 Âü∫ÊñºÂµåÂÖ•ÂºèÊ™¢Á¥¢ÁöÑÂ≠êÂúñÊ™¢Á¥¢„ÄÇ\n\nÊàëÂÄëÁöÑÊñπÊ≥ïÂæûÁü•Ë≠òÂúñ‰∏≠ÊèêÂèñËàáÁî®Êà∂Êèê‰æõÁöÑÁâπÂÆö‰ø°ÊÅØÔºåÂ¶Ç \"ÂïèÈ°åÊèèËø∞\" Âíå \"ÂïèÈ°åÊëòË¶Å\"Ôºå‰ª•ÂèäÁî®Êà∂ÊÑèÂúñÂ¶Ç \"‰øÆÂæ©Ëß£Ê±∫ÊñπÊ°à\" Áõ∏‰∏ÄËá¥ÁöÑÁõ∏ÈóúÂ≠êÂúñ„ÄÇË©≤ÈÅéÁ®ãÂåÖÊã¨ÂÖ©ÂÄã‰∏ªË¶ÅÊ≠•È©üÔºöÂü∫ÊñºÂµåÂÖ•ÂºèÊ™¢Á¥¢ÁöÑÂ∑•ÂñÆË≠òÂà•ÂíåÁî±LLMÈ©ÖÂãïÁöÑÂ≠êÂúñÊèêÂèñ„ÄÇ\n\nÂü∫Ê∫ñÂíåÂØ¶È©óÁµêÊûúÂú®K=1ÂíåK=3ÊôÇÁöÑMRR„ÄÅRecall@KÂíåNDCG@KÁöÑÊØîËºÉÔºå\nÂåÖÂê´‰ª•‰∏ãË°®Ê†ºÊ®ôÈ°åÔºö\nÂü∫Ê∫ñËàáÂØ¶È©óÁµêÊûúÊØîËºÉÔºå\nÂåÖÂê´‰ª•‰∏ãÊ¨Ñ‰ΩçÔºö\n- MRRÔºöÂü∫Ê∫ñÂíåÂØ¶È©óÁöÑÂπ≥ÂùáÂÄíÊï∏ÊéíÂêçÔºàMRRÔºâÂÄº\n- Recall@KÔºöÂú®K=1ÂíåK=3ÊôÇÂü∫Ê∫ñÂíåÂØ¶È©óÁöÑÂè¨ÂõûÁéáÂÄº\n- NDCG@KÔºöÂú®K=1ÂíåK=3ÊôÇÂü∫Ê∫ñÂíåÂØ¶È©óÁöÑÊ≠∏‰∏ÄÂåñÊäòÊâ£Á©çÂàÜÂ¢ûÁõäÔºàNDCGÔºâÂÄº\n\nÂü∫Ê∫ñÁµêÊûúÂíåÂØ¶È©óÁµêÊûúÁöÑMRR„ÄÅRecall@KÂíåNDCG@KÂú®K=1ÂíåK=3ÁöÑÊØîËºÉÂ¶Ç‰∏ãË°®ÊâÄÁ§∫Ôºö\nË°®Ê†ºÊ®ôÈ°åÔºöÂü∫Ê∫ñ vs. ÂØ¶È©óÁµêÊûú\n\n|    |MRR    |Recall@K    |NDCG@K    |\n|---|---|---|---|\n|K=1    |0.522    |0.640    |0.520    |\n|K=3    |0.400    |0.400    |NA    |\n|    |Baseline    |0.927    |1.000    |0.946    |\n|    |Experiment    |0.860    |0.860    |NA    |\n\nÂú®Áî±LLMÈ©ÖÂãïÁöÑÂ≠êÂúñÊèêÂèñÊ≠•È©ü‰∏≠ÔºåÁ≥ªÁµ±È¶ñÂÖàÂ∞áÂéüÂßã‰ΩøÁî®ËÄÖÊü•Ë©¢ùëûÈáçÊñ∞Ë°®Ëø∞Ôºå‰ª•ÂåÖÂê´Ê™¢Á¥¢Âà∞ÁöÑÁ•®Ë≠âIDÔºõÁÑ∂ÂæåÂ∞á‰øÆÊîπÂæåÁöÑÊü•Ë©¢ùëû'ÁøªË≠ØÁÇ∫ÂúñÂΩ¢Êï∏ÊìöÂ∫´Ë™ûË®ÄÔºå‰æãÂ¶ÇCypherÁî®ÊñºNeo4jÈÄ≤Ë°åÂïèÁ≠î„ÄÇ\n\nÈÄôÂÄãË°®Ê†ºÊØîËºÉ‰∫ÜÂü∫Ê∫ñÁâàÂíåÂØ¶È©óÁâà‰πãÈñìÁöÑÊÄßËÉΩÊåáÊ®ôÔºàBLEU„ÄÅMETEOR„ÄÅROUGEÔºâÔºå\nË°®Ê†ºÊ®ôÈ°åÁÇ∫Ôºö\nÊÄßËÉΩÊåáÊ®ôÊØîËºÉÔºå\nÂåÖÊã¨‰ª•‰∏ãÂàóÔºö\n- BLEUÔºöÁÑ°\n- METEORÔºöÁÑ°\n- ROUGEÔºöÁÑ°\n\nÈÄôÂºµË°®Ê†ºÊØîËºÉ‰∫ÜÂü∫Ê∫ñÁµÑËàáÂØ¶È©óÁµÑ‰πãÈñìÁöÑË°®ÁèæÊåáÊ®ôÔºàBLEU„ÄÅMETEOR„ÄÅROUGEÔºâÔºå\nË°®Ê†ºÊ®ôÈ°åÁÇ∫ÔºöË°®ÁèæÊåáÊ®ôÊØîËºÉÔºå\nÂåÖÂê´‰ª•‰∏ãÂàóÔºö\n- BLEU: ÁÑ°\n- METEOR: ÁÑ°\n- ROUGE: ÁÑ°\n\n| |BLEU|METEOR|ROUGE|\n|---|---|---|---|\n|Âü∫Ê∫ñÁµÑ|0.057|0.279|0.183|\n|ÂØ¶È©óÁµÑ|0.377|0.613|0.546|\n\nÁîüÁî¢‰ΩøÁî®Ê°à‰æã\n\nÊàëÂÄëÂú® LinkedIn ÁöÑÂÆ¢Êà∂ÊúçÂãôÂúòÈöä‰∏≠ÈÉ®ÁΩ≤‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÔºåÊ∂µËìãÂ§öÂÄãÁî¢ÂìÅÁ∑ö„ÄÇÂúòÈöäË¢´Èö®Ê©üÂàÜÊàêÂÖ©ÁµÑÔºö‰∏ÄÁµÑ‰ΩøÁî®ÊàëÂÄëÁöÑÁ≥ªÁµ±ÔºåÂè¶‰∏ÄÁµÑÂ†ÖÊåÅ‰ΩøÁî®ÂÇ≥Áµ±ÁöÑÊâãÂãïÊñπÊ≥ï„ÄÇÂ¶ÇÁ¨¨3Ë°®ÊâÄÁ§∫Ôºå‰ΩøÁî®ÊàëÂÄëÁ≥ªÁµ±ÁöÑÂúòÈöäÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊî∂ÁõäÔºåÂ∞áÊØèÂÄãÂïèÈ°åÁöÑ‰∏≠‰ΩçËß£Ê±∫ÊôÇÈñìÊ∏õÂ∞ë‰∫Ü28.6%„ÄÇÈÄôÁ™ÅÈ°Ø‰∫ÜÊàëÂÄëÁ≥ªÁµ±Âú®ÊèêÈ´òÂÆ¢Êà∂ÊúçÂãôÊïàÁéáÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ\n\nË©≤Ë°®Ê†ºÊØîËºÉ‰∫Ü‰ΩøÁî®Â∑•ÂÖ∑Âíå‰∏ç‰ΩøÁî®Â∑•ÂÖ∑ÊôÇÂÆåÊàê‰ªªÂãôÊâÄÈúÄÁöÑÊôÇÈñìÔºå\nËàá‰ª•‰∏ãË°®Ê†ºÊ®ôÈ°åÔºö\n‰ΩøÁî®Ëàá‰∏ç‰ΩøÁî®Â∑•ÂÖ∑ÁöÑ‰ªªÂãôÊôÇÈñìÊØîËºÉÔºå\nÂÖ∑Êúâ‰ª•‰∏ãÂàóÔºö\n- ÁµÑÂà•ÔºöÁÑ°\n- Âπ≥ÂùáÂÄºÔºöÁÑ°\n- P50ÔºöÁÑ°\n- P90ÔºöÁÑ°\n\n‰ª•‰∏ãÊòØÊØîËºÉ‰ΩøÁî®Â∑•ÂÖ∑Âíå‰∏ç‰ΩøÁî®Â∑•ÂÖ∑ÂÆåÊàê‰ªªÂãôÊâÄÈúÄÊôÇÈñìÁöÑË°®Ê†º:\n\n| Áæ§ÁµÑ | Âπ≥ÂùáÂÄº | P50 | P90 |\n|---|---|---|---|\n| Êú™‰ΩøÁî®Â∑•ÂÖ∑ | 40Â∞èÊôÇ | 7Â∞èÊôÇ | 87Â∞èÊôÇ |\n| ‰ΩøÁî®Â∑•ÂÖ∑ | 15Â∞èÊôÇ | 5Â∞èÊôÇ | 47Â∞èÊôÇ |\n\nÁ≠îÊ°àÁîüÊàê„ÄÇÁ≠îÊ°àÊòØÈÄöÈÅéÂ∞áÂæûÁ¨¨3.2.2ÁØÄÊ™¢Á¥¢ÁöÑÊï∏ÊìöËàáÂàùÂßãÊü•Ë©¢Áõ∏ÈóúËÅØ‰æÜÁ∂úÂêàÂêàÊàêÁöÑ„ÄÇLLM‰ΩúÁÇ∫Ëß£Á¢ºÂô®ÔºåÊ†πÊìöÁç≤ÂèñÁöÑ‰ø°ÊÅØ‰æÜÂà∂ÂÆöÂ∞çÁî®Êà∂Êü•Ë©¢ÁöÑÂõûÁ≠î„ÄÇÂ∞çÊñºÂº∑Â§ßÁöÑÂú®Á∑öÊúçÂãôÔºåÂ¶ÇÊûúÊü•Ë©¢Âü∑Ë°åÈÅáÂà∞ÂïèÈ°åÔºåÂõûÈÄÄÊ©üÂà∂Â∞áÊÅ¢Âæ©Âà∞Âü∫Á§éÁöÑÂü∫ÊñºÊñáÊú¨ÁöÑÊ™¢Á¥¢ÊñπÊ≥ï„ÄÇ\n\nÂØ¶È©ó\n\nÂØ¶È©óË®≠Ë®à\n\nÊàëÂÄëÁöÑË©ï‰º∞ÈááÁî®‰∫Ü‰∏ÄÂÄãÁî±ÂÖ∏ÂûãÊü•Ë©¢„ÄÅÊîØÊåÅÂ∑•ÂñÆÂèäÂÖ∂Ê¨äÂ®ÅËß£Ê±∫ÊñπÊ°àÁµÑÊàêÁöÑÁ≤æÈÅ∏‚ÄúÈªÉÈáë‚ÄùÊï∏ÊìöÈõÜ„ÄÇÂ∞çÁÖßÁµÑ‰ΩøÁî®ÂÇ≥Áµ±ÁöÑÂü∫ÊñºÊñáÊú¨ÁöÑEBRÔºåËÄåÂØ¶È©óÁµÑÊáâÁî®‰∫ÜÊú¨Á†îÁ©∂‰∏≠Ê¶ÇËø∞ÁöÑÊñπÊ≥ï„ÄÇÂ∞çÊñºÂÖ©ÁµÑÔºåÊàëÂÄë‰ΩøÁî®‰∫ÜÁõ∏ÂêåÁöÑLLMÔºåÂÖ∑È´îÊòØGPT-4 [1]ÔºåÂíåÁõ∏ÂêåÁöÑÂµåÂÖ•Ê®°ÂûãÔºåÂç≥E5 [17]„ÄÇÊàëÂÄë‰ΩøÁî®Âπ≥ÂùáÂÄíÊï∏ÊéíÂêçÔºàMRRÔºâ„ÄÅÂè¨ÂõûÁéá@KÂíåNDCG@K‰æÜË°°ÈáèÊ™¢Á¥¢ÊïàÊûú„ÄÇMRRË©ï‰º∞ÂàùÂßãÊ≠£Á¢∫ÂõûÁ≠îÁöÑÂπ≥ÂùáÂÄíÊï∏ÊéíÂêçÔºåÂè¨ÂõûÁéá@KÁ¢∫ÂÆöÁõ∏ÈóúÈ†ÖÁõÆÂú®ÂâçKÂÄãÈÅ∏Êìá‰∏≠Âá∫ÁèæÁöÑÂèØËÉΩÊÄßÔºåNDCG@KÈÄöÈÅéÂêåÊôÇËÄÉÊÖÆÈ†ÖÁõÆÁöÑ‰ΩçÁΩÆÂíåÁõ∏ÈóúÊÄß‰æÜË©ï‰º∞ÊéíÂêçË≥™Èáè„ÄÇÂ∞çÊñºÂïèÁ≠îÊÄßËÉΩÔºåÊàëÂÄëÂ∞á‚ÄúÈªÉÈáë‚ÄùËß£Ê±∫ÊñπÊ°àËàáÁîüÊàêÁöÑÂõûÁ≠îÈÄ≤Ë°åÂ∞çÊØîÔºå‰ΩøÁî®BLEU [11]„ÄÅROUGE [9]ÂíåMETEOR [3]Á≠âÊåáÊ®ôÈÄ≤Ë°åË©ïÂàÜ„ÄÇ\n\nÁµêÊûúÂíåÂàÜÊûê\n\nÊ™¢Á¥¢ÂíåÂïèÁ≠îË°®ÁèæË´ãË¶ãË°®1ÂíåË°®2„ÄÇÂú®ÊâÄÊúâÊåáÊ®ô‰∏äÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂ±ïÁ§∫‰∫Ü‰∏ÄËá¥ÁöÑÊîπÈÄ≤„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂÆÉÂú®MRRÊñπÈù¢Ë∂ÖË∂ä‰∫ÜÂü∫Ê∫ñ77.6ÔºÖÔºåÂú®BLEUË©ïÂàÜÊñπÈù¢Ë∂ÖÈÅé‰∫Ü0.32ÔºåË≠âÂØ¶‰∫ÜÂÖ∂ÂÑ™Ë∂äÁöÑÊ™¢Á¥¢ÊïàËÉΩÂíåÂïèÁ≠îÊ∫ñÁ¢∫ÊÄß„ÄÇ\n\nÁµêË´ñÂíåÊú™‰æÜÂ∑•‰Ωú\n\nÁ∏Ω‰πãÔºåÊàëÂÄëÁöÑÁ†îÁ©∂È°ØËëóÊé®ÈÄ≤‰∫ÜÂÆ¢Êà∂ÊúçÂãôÁöÑËá™ÂãïÂïèÁ≠îÁ≥ªÁµ±„ÄÇÂ∞áÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºàRAGÔºâËàáÁü•Ë≠òÂúñÔºàKGÔºâÁõ∏ÁµêÂêàÂ∑≤ÊèêÂçá‰∫ÜÊ™¢Á¥¢ÂíåÂõûÁ≠îÊåáÊ®ôÔºåÊèêÈ´ò‰∫ÜÊï¥È´îÊúçÂãôÊïàÊûú„ÄÇÊú™‰æÜÁöÑÂ∑•‰ΩúÂ∞áÂ∞àÊ≥®ÊñºÔºöÈñãÁôº‰∏ÄÂÄãËá™ÂãïÊ©üÂà∂‰æÜÊèêÂèñÂúñÂΩ¢Ê®°ÊùøÔºåÂ¢ûÂº∑Á≥ªÁµ±ÁöÑÈÅ©ÊáâÊÄßÔºõÊ†πÊìöÁî®Êà∂Êü•Ë©¢Á†îÁ©∂Âü∫ÊñºÁü•Ë≠òÂúñÁöÑÂãïÊÖãÊõ¥Êñ∞Ôºå‰ª•ÊîπÂñÑÂØ¶ÊôÇÈüøÊáâËÉΩÂäõÔºõÊé¢Á¥¢Á≥ªÁµ±Âú®ÂÆ¢Êà∂ÊúçÂãô‰πãÂ§ñÂÖ∂‰ªñÊÉÖÂ¢É‰∏≠ÁöÑÊáâÁî®ÊÄß„ÄÇ\n\nÂÖ¨Âè∏Á∞°‰ªã\n\nÈóúÊñºLinkedIn: ÊàêÁ´ãÊñº2003Âπ¥ÔºåLinkedInÈÄ£Êé•ÂÖ®ÁêÉÂ∞àÊ•≠‰∫∫Â£´Ôºå‰Ωø‰ªñÂÄëÊõ¥ÂÖ∑ÁîüÁî¢ÂäõÂíåÊàêÂäü„ÄÇÊìÅÊúâË∂ÖÈÅé10ÂÑÑÂÖ®ÁêÉÊúÉÂì°ÔºåÂåÖÊã¨‰æÜËá™ÊØè‰∏ÄÂÆ∂Ë≤°ÂØå500Âº∑‰ºÅÊ•≠ÁöÑÈ´òÁÆ°Âú®ÂÖßÔºåLinkedInÊòØÂÖ®ÁêÉÊúÄÂ§ßÁöÑÂ∞àÊ•≠Á∂≤Áµ°„ÄÇË©≤ÂÖ¨Âè∏ÊìÅÊúâÂ§öÊ®£ÂåñÁöÑÊ•≠ÂãôÊ®°ÂºèÔºåÊî∂ÂÖ•‰æÜËá™‰∫∫ÊâçËß£Ê±∫ÊñπÊ°à„ÄÅÁáüÈä∑Ëß£Ê±∫ÊñπÊ°à„ÄÅÈä∑ÂîÆËß£Ê±∫ÊñπÊ°àÂíåÈ´òÁ¥öË®ÇÈñ±Áî¢ÂìÅ„ÄÇÁ∏ΩÈÉ®‰ΩçÊñºÁüΩË∞∑ÔºåLinkedInÂú®ÂÖ®ÁêÉÂêÑÂú∞Ë®≠ÊúâËæ¶‰∫ãËôï„ÄÇÊ¨≤‰∫ÜËß£Êõ¥Â§ö‰ø°ÊÅØÔºåË´ãË®™Âïèhttps://www.linkedin.com/company/linkedin/about/„ÄÇ\n\nÊºîÁ§∫‰∫∫Á∞°‰ªã\n\nÂæêÊåØÊø§ÊòØLinkedInÁöÑÈ´òÁ¥öËªüÈ´îÂ∑•Á®ãÂ∏´„ÄÇ‰ªñÂú®ÂØÜÊ≠áÊ†πÂ§ßÂ≠∏Áç≤ÂæóÊ©üÂô®‰∫∫Â≠∏Á¢©Â£´Â≠∏‰ΩçÂíåÈõªÊ©üÂ∑•Á®ãËàáË®àÁÆóÊ©üÁßëÂ≠∏ÔºàEECSÔºâÂ≠∏Â£´Â≠∏‰Ωç„ÄÇ‰ªñÁöÑÁ†îÁ©∂ËààË∂£ÂåÖÊã¨Â§ßÂûãË™ûË®ÄÊ®°ÂûãÂíåËá™ÁÑ∂Ë™ûË®ÄÁîüÊàê„ÄÇ\n\nÂèÉËÄÉÊñáÁçª\n\n[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Á≠â‰∫∫„ÄÇ2023„ÄÇGPT-4ÊäÄË°ìÂ†±Âëä„ÄÇarXivÈ†êÂç∞Êú¨arXiv:2303.08774 (2023)„ÄÇ\n[2] Atlassian„ÄÇ2024„ÄÇJira | È†ÖÁõÆË∑üË∏™ËªüÈ´î„ÄÇhttps://www.atlassian.com/software/jira„ÄÇË®™ÂïèÊó•ÊúüÔºö2024Âπ¥01Êúà04Êó•„ÄÇ\n[3] Satanjeev BanerjeeÂíåAlon Lavie„ÄÇ2005„ÄÇMETEOR:‰∏ÄÁ®ÆÁî®ÊñºÊ©üÂô®ÁøªË≠ØË©ï‰º∞ÁöÑËá™ÂãïÂ∫¶ÈáèÊ®ôÊ∫ñÔºå‰∏¶ÊèêÈ´òËàá‰∫∫È°ûÂà§Êñ∑‰πãÈñìÁöÑÁõ∏ÈóúÊÄß„ÄÇÂú®pe acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarizationÁöÑË´ñÊñáÈõÜ‰∏≠„ÄÇ65-72È†Å„ÄÇ\n[4] Nikita Bhutani, Xinyi Zheng, Kun Qian, Yunyao LiÂíåH Jagadish„ÄÇ2020„ÄÇÈÄöÈÅéÁµêÂêà‰æÜËá™Á≤æÂøÉÁ≠ñÂäÉÂíåÊèêÂèñÁöÑÁü•Ë≠òÂ∫´‰ø°ÊÅØ‰æÜÂõûÁ≠îË§áÈõúÂïèÈ°å„ÄÇÂú®Á¨¨‰∏ÄÂ±ÜËá™ÁÑ∂Ë™ûË®ÄÊé•Âè£Á†îË®éÊúÉÁöÑË´ñÊñáÈõÜ‰∏≠„ÄÇ1-10È†Å„ÄÇ\n[5] Antoine Bordes, Jason WestonÂíåNicolas Usunier„ÄÇ2014„ÄÇ‰ΩøÁî®Âº±Áõ£Áù£ÂµåÂÖ•Ê®°ÂûãÈÄ≤Ë°åÈñãÊîæÂïèÁ≠î„ÄÇÂú®Ê≠êÊ¥≤ÊúÉË≠∞ECML PKDD 2014ÁöÑÊ©üÂô®Â≠∏ÁøíÂíåÁü•Ë≠òÁôºÁèæ‰∏≠Ôºö2014Âπ¥9Êúà15-19Êó•ÔºåÊ≥ïÂúãÂçóÈå´„ÄÇÈÉ®ÂàÜI 14„ÄÇ\n\n2005Âπ¥„ÄÇMETEORÔºö‰∏ÄÁ®ÆËá™ÂãïË©ï‰º∞Ê©üÂô®ÁøªË≠ØÁöÑÂ∫¶ÈáèÊ®ôÊ∫ñÔºåÂÖ∑ÊúâËºÉÈ´òÁöÑËàá‰∫∫È°ûÂà§Êñ∑Áõ∏ÈóúÊÄß„ÄÇÂú®ACLÁ†îË®éÊúÉÂ∑•‰ΩúÂùä \"intrisic and extrinsic evaluation measures for machine translation and/or summarization\" ÁöÑË´ñÊñáÈõÜ‰∏ä„ÄÇ65-72È†Å„ÄÇ\n\n[4] Nikita Bhutani, Xinyi Zheng, Kun Qian, Yunyao Li Âíå H Jagadish. 2020. ÈÄöÈÅéÁµêÂêàÂæûÁ∑®Á∫ÇÂíåÊèêÂèñÁöÑÁü•Ë≠òÂ∫´‰ø°ÊÅØ‰æÜÂõûÁ≠îË§áÈõúÂïèÈ°å„ÄÇÊî∂ÈåÑÊñºÁ¨¨‰∏ÄÂ±ÜËá™ÁÑ∂Ë™ûË®ÄÁïåÈù¢Á†îË®éÊúÉË´ñÊñáÈõÜ„ÄÇ1-10È†Å„ÄÇ\n\n[5] Antoine Bordes, Jason WestonÂíåNicolas Usunier„ÄÇ2014. ‰ΩøÁî®Âº±Áõ£Áù£ÂµåÂÖ•Ê®°ÂûãÁöÑÈñãÊîæÂºèÂïèÁ≠î„ÄÇÊî∂ÈåÑÊñº„ÄäÊ©üÂô®Â≠∏ÁøíÂíåÁü•Ë≠òÁôºÁèæÂú®Êï∏ÊìöÂ∫´‰∏≠ÁöÑÊáâÁî®ÔºöÊ≠êÊ¥≤ÊúÉË≠∞ECML PKDD 2014Ë´ñÊñáÈõÜÔºåÁ¨¨IÈÉ®ÂàÜ„Äã„ÄÇSpringerÔºå165-180È†Å„ÄÇ\n\n[6] Jacob Devlin, Ming-Wei Chang, Kenton LeeÂíåKristina Toutanova„ÄÇ2018. BERTÔºöÊ∑±Â∫¶ÈõôÂêëTransformerÁöÑË™ûË®ÄÁêÜËß£È†êË®ìÁ∑¥„ÄÇarXiv preprint arXiv:1810.04805 (2018)„ÄÇ\n\n[7] Bowen Jin, Gang Liu, Chi Han, Meng Jiang, Heng JiÂíåJiawei Han„ÄÇ2023„ÄÇÂúñ‰∏äÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºö‰∏ÄÈ†ÖÂÖ®Èù¢Ë™øÊü•„ÄÇarXiv preprint arXiv:2312.02783 (2023)„ÄÇ\n\n[8] Patrick Lewis, Epan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K√ºttler, Mike Lewis, Wen-tau Yih, Tim Rockt√§schelÁ≠â„ÄÇ2020„ÄÇÁü•Ë≠òÂØÜÈõÜÂûãNLP‰ªªÂãôÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê„ÄÇ„ÄäÁ•ûÁ∂ì‰ø°ÊÅØËôïÁêÜÁ≥ªÁµ±ÈÄ≤Â±ï„ÄãÁ¨¨33Âç∑ (2020)Ôºå9459-9474È†Å„ÄÇ\n\n[9] Chin-Yew Lin„ÄÇ2004„ÄÇRougeÔºöËá™ÂãïÊëòË¶ÅË©ï‰º∞ÁöÑ‰∏ÄÂÄãÂ•ó‰ª∂„ÄÇÂú®ÊñáÊú¨ÊëòË¶ÅÂàÜÊîØ‰∏≠„ÄÇ74-81È†Å„ÄÇ\n\n[10] Linhao Luo, Yuan-Fang Li, Gholamreza HaffariÂíåShirui Pan„ÄÇ2023„ÄÇÂúñ‰∏äÁöÑÊé®ÁêÜÔºöFaipfulÂíåÂèØËß£ÈáãÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÊé®ÁêÜ„ÄÇarXiv preprint arXiv:2310.01061 (2023)„ÄÇ\n\n[11] Kishore Papineni, Salim Roukos, Todd WardÂíåWei-Jing Zhu„ÄÇ2002„ÄÇBleuÔºöËá™ÂãïÊ©üÂô®ÁøªË≠ØË©ï‰º∞ÊñπÊ≥ï„ÄÇÂú®‚ÄúË®àÁÆóË™ûË®ÄÂ≠∏Âπ¥ÊúÉÁ¨¨40Â±ÜÂπ¥ÊúÉË´ñÊñáÈõÜ‚Äù„ÄÇ311-318È†Å„ÄÇ\n\n[12] QdrantÂúòÈöä„ÄÇ2024„ÄÇQdrant - ÂêëÈáèÊï∏ÊìöÂ∫´„ÄÇhttps://qdrant.tech/„ÄÇÊ™¢Á¥¢Êó•ÊúüÔºö2024Âπ¥1Êúà8Êó•„ÄÇ\n\n[13] Zhixiao Qi, Yijiong Yu, Meiqi Tu, Junyi TanÂíåYongfeng Huang„ÄÇ2023„ÄÇFoodGPTÔºöÂú®È£üÂìÅÊ∏¨Ë©¶È†òÂüüÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÂÖ∑ÊúâÂ¢ûÈáèÂºèÈ†êË®ìÁ∑¥ÂíåÁü•Ë≠òÂúñÊèêÁ§∫„ÄÇarXiv preprint arXiv:2308.10173 (2023)„ÄÇ\n\n[14] Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn Mazaitis, Ruslan SalakhutdinovÂíåWilliam Cohen„ÄÇ2018„ÄÇ‰ΩøÁî®Áü•Ë≠òÂ∫´ÂíåÊñáÊú¨ÁöÑÊó©ÊúüËûçÂêàÈÄ≤Ë°åÈñãÊîæÂüüÂïèÁ≠î„ÄÇ„Ää2018Âπ¥Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÂØ¶Ë≠âÊñπÊ≥ïÊúÉË≠∞Ë´ñÊñáÈõÜ„ÄãÔºåÁî±Ellen Riloff, David Chiang, Julia HockenmaierÂíåJun‚Äôichi TsujiiÔºàÁ∑®ËºØÔºâ„ÄÇË®àÁÆóË™ûË®ÄÂ≠∏ÂçîÊúÉÔºåÊØîÂà©ÊôÇÂ∏ÉÈ≠ØÂ°ûÁàæÔºå4231-4242È†Å„ÄÇhttps://doi.org/10.18653/v1/D18-1455„ÄÇ\n\n[15] Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Saizhuo Wang, Chen Lin, Yeyun Gong, Heung-Yeung ShumÂíåJian Guo„ÄÇ2023„ÄÇÂúñ‰∏äÁöÑÊÄùËÄÉÔºöÂÖ∑ÊúâÁü•Ë≠òÂúñÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊ∑±Â∫¶ÂíåË≤†Ë≤¨‰ªªÊé®ÁêÜ„ÄÇarXiv preprint arXiv:2307.07697 (2023)„ÄÇ\n\n[16] Christina Unger, Lorenz B√ºhmann, Jens Lehmann, Axel-Cyrille Ngonga Ngomo, Daniel GerberÂíåPhilipp Cimiano„ÄÇ2012„ÄÇÂü∫ÊñºÊ®°ÊùøÁöÑRDFÊï∏Êìö‰∏äÁöÑÂïèÁ≠î„ÄÇÂú®‚ÄúÁ¨¨21Â±ÜÂúãÈöõËê¨Á∂≠Á∂≤Â§ßÊúÉË´ñÊñáÈõÜ‚Äù„ÄÇ639-648È†Å„ÄÇ\n\nË®àÁÆóË™ûË®ÄÂ≠∏ÂçîÊúÉÔºåÊØîÂà©ÊôÇÂ∏ÉÈ≠ØÂ°ûÁàæÔºå4231‚Äì4242„ÄÇhttps://doi.org/10.18653/v1/D18-1455\n\n[15] Â≠´ÂòâÁ¢©ÔºåÂæêÊàêÂãÅÔºåÂîêÈú≤ÊòéÔºåÁéãË≥ΩÂçìÔºåÊûóÊô®ÔºåÈæîÂ§ú‰∫ëÔºåÊ≤àÂêëÈôΩÔºåÈÉ≠Âäç„ÄÇ2023Âπ¥„ÄÇThink-on-graphÔºöÁü•Ë≠òÂúñË≠úËàáÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊ∑±Â∫¶ÂíåË≤†Ë≤¨‰ªªÊé®ÁêÜ„ÄÇarXivÈ†êÂç∞Êú¨arXiv:2307.07697Ôºà2023Ôºâ„ÄÇ\n\n[16] ÂÖãÈáåÊñØËíÇÂ®ú¬∑ÁÉèÊ†ºÔºàChristina UngerÔºâÔºåÁæÖÂÄ´Ëå®¬∑Â∏ÉÊõºÔºàLorenz B√ºhmannÔºâÔºåÂªñÈ∑≤ÔºàJens LehmannÔºâÔºåÈòøÂÖãÂ°ûÁàæ-Ë•øÈáåÁàæ¬∑ÊÅ©ÊààÁ¥ç¬∑ÊÅ©Âì•Ëé´ÔºàAxel-Cyrille Ngonga NgomoÔºâÔºå‰∏πÂ∞ºÁàæ¬∑Ê†ºÁàæ‰ºØÔºàDaniel GerberÔºâÂíåËè≤Âà©ÊôÆ¬∑Ë•øÁ±≥‰∫ûË´æÔºàPhilipp CimianoÔºâ„ÄÇ2012Âπ¥„ÄÇÂü∫ÊñºÊ®°ÊùøÁöÑRDFÊï∏ÊìöÂïèÁ≠î„ÄÇÂú®Á¨¨21Â±Ü‰∏ñÁïåÁ∂≤ÈöõÁ∂≤Ë∑ØÂ§ßÊúÉË´ñÊñáÈõÜ‰∏≠„ÄÇ639‚Äì648„ÄÇ\n\n[17] Áéã‰∫ÆÔºåÊ•äÊ•†ÔºåÈªÉÊõâÈæçÔºåÁÑ¶ÂΩ¨ÊòüÔºåÊ•äÁê≥ËªçÔºåÊ±üÈÅîÊñ∞ÔºåÊãâÊ†π¬∑È¶¨Êú±ÂßÜÂæ∑ÔºàRangan MajumderÔºâÂíåÈüãÂØåËåπÔºàFuru WeiÔºâ„ÄÇ2022Âπ¥„ÄÇÂº±Áõ£Áù£Â∞çÊØîÈ†êË®ìÁ∑¥‰∏ãÁöÑÊñáÊú¨ÂµåÂÖ•„ÄÇarXivÈ†êÂç∞Êú¨arXiv:2212.03533Ôºà2022Ôºâ„ÄÇ\n\n[18] ËÅûÊØÖÈ∫üÔºåÁéãËá™Â∞ÅÔºåÂ≠´ÈöõÁåõ„ÄÇ2023Âπ¥„ÄÇÊÄùÁ∂≠Â∞éÂúñÔºöÁü•Ë≠òÂúñË≠ú‰øÉÁôºÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰∏≠ÁöÑÊÄùÁ∂≠Âúñ„ÄÇarXivÈ†êÂç∞Êú¨arXiv:2308.09729Ôºà2023Ôºâ„ÄÇ\n\n[19] ÂæêÂ†ÉÔºåÈ¶ÆË®ÄÊùæÔºåÈªÉÊùæÊñπÔºåË∂ôÊù±Â≤©„ÄÇ2016Âπ¥„ÄÇÂü∫ÊñºÁü•Ë≠òÂ∫´ÂíåËá™Áî±ÊñáÊú¨ÁöÑÊ∑∑ÂêàÂïèÁ≠î„ÄÇÂú®Á¨¨26Â±ÜË®àÁÆóË™ûË®ÄÂ≠∏ÂúãÈöõÊúÉË≠∞ÔºàCOLING 2016ÔºâË´ñÊñáÈõÜ‰∏≠„ÄÇ2397‚Äì2407„ÄÇ\n\n[20] Ê•äÊûóÊõúÔºåÈô≥Ê¥™Ê¥ãÔºåÊùéÈáóÔºå‰∏ÅÈúÑÔºåÂê≥Êñ∞Êù±„ÄÇ2023Âπ¥„ÄÇChatGPT‰∏çË∂≥‰ª•ÊáâÂ∞çÔºöÂà©Áî®Áü•Ë≠òÂúñË≠úÂ¢ûÂº∑Â§ßÂûãË™ûË®ÄÊ®°ÂûãÈÄ≤Ë°å‰∫ãÂØ¶ÊÑüÁü•Ë™ûË®ÄÂª∫Ê®°„ÄÇarXivÈ†êÂç∞Êú¨arXiv:2306.11489Ôºà2023Ôºâ„ÄÇ\n\n[21] ÊòìÊñáË®éÔºàScott Wen-tau YihÔºâÔºåÂºµÊòéÂÅâÔºåË≥ÄÊõâÊù±ÔºåÈ´òÂª∫Èãí„ÄÇ2015Âπ¥„ÄÇÈÄöÈÅéÂàÜÊÆµÊü•Ë©¢ÂúñÁîüÊàêÈÄ≤Ë°åË™ûÁæ©Ëß£ÊûêÔºöËàáÁü•Ë≠òÂ∫´ÁöÑÂïèÁ≠î„ÄÇÂú®ACLÁ¨¨53Â±ÜÂπ¥ÊúÉÂíåAFNLPÁ¨¨7Â±ÜÂúãÈöõËÅØÂêàÊúÉË≠∞ÁöÑÁ®ãÂ∫è‰∏≠„ÄÇ"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ÂÑ≤Â≠òÁøªË≠ØÁµêÊûú\n",
        "\n",
        "import os\n",
        "DONE_LOC = os.path.join(THESIS_LOC, 'done')\n",
        "\n",
        "if not os.path.exists(DONE_LOC):\n",
        "  os.makedirs(DONE_LOC)\n",
        "\n",
        "with open(os.path.join(THESIS_LOC, PDF_FILE + '.md'), 'w') as f:\n",
        "  f.write('\\n\\n'.join([ t for t in translated_text] ))\n",
        "\n",
        "os.rename(os.path.join(THESIS_LOC, PDF_FILE), os.path.join(DONE_LOC, PDF_FILE) )\n",
        "\n",
        "os.listdir(THESIS_LOC)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "1fC46HeE0j8r",
        "outputId": "639deb76-06db-42c7-e8d4-0a7b6178c1a2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['done', '2404.17723.pdf.md']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lgu540bf93XT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}